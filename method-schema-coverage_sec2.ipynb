{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0703df9-dc31-4bdd-a53c-568bea718cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'Error parsing the query.' occurrences: 291\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Function to count occurrences of a specific string in a CSV file\n",
    "def count_error_occurrences(file_path, target_string):\n",
    "    error_count = 0\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            for cell in row:\n",
    "                if target_string in cell:\n",
    "                    error_count += 1\n",
    "    return error_count\n",
    "\n",
    "# Specify the path to your parsed CSV file\n",
    "csv_file_path = 'parsed.csv'\n",
    "\n",
    "# Specify the target string you want to count\n",
    "target_string = 'Error parsing the query.'\n",
    "\n",
    "# Call the function to count occurrences\n",
    "error_count = count_error_occurrences(csv_file_path, target_string)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of '{target_string}' occurrences: {error_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280e198-d380-44d0-8985-454dc10d7fb3",
   "metadata": {},
   "source": [
    "# Global variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6c06f-e5b3-4d32-9fd7-4ed7958661f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def normalize_sparql_queries(input_csv_path, output_csv_path):\n",
    "    global_var_counter = 1  # Initialize the global variable counter\n",
    "\n",
    "    with open(input_csv_path, 'r') as input_csv, open(output_csv_path, 'w', newline='') as output_csv:\n",
    "        csv_reader = csv.reader(input_csv)\n",
    "        csv_writer = csv.writer(output_csv)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue  # Skip empty rows\n",
    "\n",
    "            sparql_query = row[1]  # Assuming the SPARQL query is in the first column\n",
    "\n",
    "            # Extract variables from the SPARQL query using regular expressions\n",
    "            variables = re.findall(r'\\?([a-zA-Z_][a-zA-Z0-9_]*)', sparql_query)\n",
    "\n",
    "            # Create a mapping of old variables to new numerated variables\n",
    "            variable_mapping = {}\n",
    "            for variable in variables:\n",
    "                if variable not in variable_mapping:\n",
    "                    variable_mapping[variable] = f'?var{global_var_counter}'\n",
    "                    global_var_counter += 1\n",
    "\n",
    "            # Replace variables in the SPARQL query with numerated variables\n",
    "            for old_variable, new_variable in variable_mapping.items():\n",
    "                sparql_query = sparql_query.replace(f'?{old_variable}', new_variable)\n",
    "\n",
    "            # Write the normalized query to the output CSV\n",
    "            csv_writer.writerow([sparql_query])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv_path = \"unique_normalised_12_9_2023.csv\"  # Replace with the path to your input CSV file\n",
    "    output_csv_path = \"normalized_queries.csv\"  # Replace with the desired output CSV file\n",
    "\n",
    "    normalize_sparql_queries(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdf7fe-5ec0-41fc-a9ac-f7a53c98bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the maximum column width to None to display the entire content of each cell\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('normalized_queries.csv', lineterminator='\\n', dtype=str, header=None)\n",
    "\n",
    "print(len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f6a37-96e8-44b7-8ef1-81037e7fb698",
   "metadata": {},
   "source": [
    "get a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20e22256-7536-4134-b039-5f3769d67d83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows have been saved to t.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_csv_file = 'find_bug_triples.csv'  # Replace with your input CSV file path\n",
    "output_csv_file = 't.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Get the first 1000 rows, including the header\n",
    "sample_df = df.head(10 )\n",
    "\n",
    "# Save the sample DataFrame to an output CSV file\n",
    "sample_df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"{len(sample_df)} rows have been saved to {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dde436-96e1-4ff3-9a4a-a475203b534f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# get triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422c8fa-56f6-4fcc-9f1a-e619ca89fa1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Load your CSV data from the input file\n",
    "input_csv_file = 'parsed.csv'\n",
    "output_csv_file = 'find_bug_triples.csv'\n",
    "\n",
    "# Create a list to store the triples\n",
    "triples = []\n",
    "\n",
    "# Define a function to extract triples from the parse tree\n",
    "def extract_triples(parse_tree):\n",
    "    if \"triples\" in parse_tree:\n",
    "        for triple in parse_tree[\"triples\"]:\n",
    "            try:\n",
    "                subject = triple[\"subject\"][\"value\"]\n",
    "                predicate = triple[\"predicate\"][\"value\"]\n",
    "                obj = triple[\"object\"][\"value\"]\n",
    "                triples.append((subject, predicate, obj))\n",
    "            except KeyError as e:\n",
    "                print(f\"Error extracting triple: {e}\")\n",
    "                print(\"Offending triple:\", triple)\n",
    "    \n",
    "    # Recursively call the function on child nodes\n",
    "    for key, value in parse_tree.items():\n",
    "        if isinstance(value, dict):\n",
    "            extract_triples(value)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    extract_triples(item)\n",
    "\n",
    "# Read the CSV file and process each row\n",
    "with open(input_csv_file, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        # Check if there is content in the second column and it doesn't contain the error message\n",
    "        if len(row) > 1 and row[1] and \"Error parsing the query\" not in row[1]:\n",
    "            # Extract triples from the content of the second column\n",
    "            content = row[1]\n",
    "            try:\n",
    "                parse_tree = json.loads(content)\n",
    "                extract_triples(parse_tree)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle invalid JSON if needed\n",
    "                pass\n",
    "\n",
    "# Write the extracted triples to the output CSV file\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['subject', 'predicate', 'object']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the triples\n",
    "    for triple in triples:\n",
    "        writer.writerow({'subject': triple[0], 'predicate': triple[1], 'object': triple[2]})\n",
    "\n",
    "print(\"Triples extracted and written to\", output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a5129a-006f-41c1-9845-f8af30cbe4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the input and output file names\n",
    "input_file = 'find_bug_triples.csv'\n",
    "output_file = 'filtered_data.csv'\n",
    "\n",
    "# Open the input data file for reading and the output file for writing\n",
    "with open(input_file, 'r') as input_file, open(output_file, 'w') as output_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into components using tab (',') as the delimiter\n",
    "        components = line.strip().split(',')\n",
    "\n",
    "        # Check if the line has exactly three components (subject, predicate, object)\n",
    "        if len(components) == 3:\n",
    "            # Write complete triples to the output file\n",
    "            output_file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c100c4-ff82-426e-ab3d-7f8c56d392f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# entity extraction from triples:\n",
    "if entity start with var do not write it in output file.\n",
    "\n",
    "if entity start with g_ do not write it in output file.\n",
    "\n",
    "if a entity has this substring \"nonsensical\" do not write it in output file.\n",
    "\n",
    "only write unique entities in output csv\n",
    "\n",
    "entities with spaces like are encoded to improve clustering \"DrugBank drugbank_vocabulary:Indication\"\n",
    "\n",
    "2177101 entities redeuced to 30918\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2769492e-e51b-4918-97b5-b325275810a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities have been saved to extracted_entities.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_file_name = 'filtered_data.csv'\n",
    "output_file_name = 'extracted_entities.csv'\n",
    "\n",
    "subjects_and_objects = set()  # Using a set to store unique entities\n",
    "\n",
    "with open(input_file_name, mode ='r') as input_file:\n",
    "    csvReader = csv.reader(input_file)\n",
    "    \n",
    "    # Skip header if there's any\n",
    "    next(csvReader, None)\n",
    "\n",
    "    for row in csvReader:\n",
    "        # Assuming that the subject is the first element and object is the third element in the row\n",
    "        subject, predicate, object_ = row\n",
    "\n",
    "        if not subject.startswith('var') and not subject.startswith('g_') and 'nonsensical' not in subject:\n",
    "            subjects_and_objects.add(subject)\n",
    "            \n",
    "        if not object_.startswith('var') and not object_.startswith('g_') and 'nonsensical' not in object_:\n",
    "            subjects_and_objects.add(object_)\n",
    "\n",
    "# Write the extracted subjects and objects to an output CSV file\n",
    "with open(output_file_name, mode ='w', newline='') as output_file:\n",
    "    csvWriter = csv.writer(output_file)\n",
    "    \n",
    "    # Writing header\n",
    "    csvWriter.writerow(['Entity'])\n",
    "    \n",
    "    # Writing data\n",
    "    for entity in subjects_and_objects:\n",
    "        csvWriter.writerow([entity])\n",
    "\n",
    "print(f\"Extracted entities have been saved to {output_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8829c1d1-e55b-4f25-abe9-a523e8da09ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entity\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://purl.org/goodrelations/v1#Offering\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLC9A4\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bio2rdf.org/kegg:K03908\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>http://bio2rdf.org/wormbase:WBGene00198889\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>http://dbpedia.org/resource/Nortriptyline\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUCLG1\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>http://bio2rdf.org/go.ref_vocabulary:Resource\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>http://bio2rdf.org/wormbase:WBGene00017619\\r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0\n",
       "0                                          Entity\\r\n",
       "1                                                \\r\n",
       "2       http://purl.org/goodrelations/v1#Offering\\r\n",
       "3                                          SLC9A4\\r\n",
       "4                  http://bio2rdf.org/kegg:K03908\\r\n",
       "..                                              ...\n",
       "95     http://bio2rdf.org/wormbase:WBGene00198889\\r\n",
       "96      http://dbpedia.org/resource/Nortriptyline\\r\n",
       "97                                         SUCLG1\\r\n",
       "98  http://bio2rdf.org/go.ref_vocabulary:Resource\\r\n",
       "99     http://bio2rdf.org/wormbase:WBGene00017619\\r\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the maximum column width to None to display the entire content of each cell\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('extracted_entities.csv', lineterminator='\\n', dtype=str, header=None)\n",
    "\n",
    "print(len(df))\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ec26c-926a-49b0-a59b-6ff2bcb13ee6",
   "metadata": {},
   "source": [
    "# query type of entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d803c-66df-4ec1-8010-1335c51e287c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install SPARQLWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d5bc70-f239-479f-a1ee-6a91b8755446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#C43568\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://bio2rdf.org/sparql\")  # Replace with the actual Bio2RDF SPARQL endpoint\n",
    "sparql.setQuery(\"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "                SELECT ?type \n",
    "                WHERE {{ \n",
    "                       ?s dcterms:title \"GPX3\" ;\n",
    "                                rdf:type ?type .\n",
    "                                                  }}\n",
    "            \"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"type\"][\"value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cad221-9dae-40f3-9b02-b7f088c9dd18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql_endpoint = \"http://bio2rdf.org/sparql\"\n",
    "\n",
    "sparql = SPARQLWrapper(sparql_endpoint)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "def is_url(string):\n",
    "    url_regex = re.compile(\n",
    "        r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    )\n",
    "    return re.match(url_regex, string) is not None\n",
    "\n",
    "def execute_query_and_write_results(entity, query):\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        results = sparql.query().convert()\n",
    "        types = set()\n",
    "        titles = set()\n",
    "\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            type_value = result.get(\"type\", {}).get(\"value\")\n",
    "            title_value = result.get(\"title\", {}).get(\"value\")\n",
    "            \n",
    "            if type_value:\n",
    "                types.add(type_value)\n",
    "            \n",
    "            if title_value:\n",
    "                titles.add(title_value)\n",
    "\n",
    "        for type_value in types:\n",
    "            types_file.write(type_value + '\\n')\n",
    "\n",
    "        for title_value in titles:\n",
    "            titles_file.write(title_value + '\\n')\n",
    "\n",
    "        if not types:\n",
    "            without_type_file.write(entity + '\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the entity {entity}: {e}\")\n",
    "\n",
    "with open('s1.csv', mode ='r') as file, \\\n",
    "     open('stypes.txt', 'w') as types_file, \\\n",
    "     open('stitles.txt', 'w') as titles_file, \\\n",
    "     open('swithout_type.txt', 'w') as without_type_file:\n",
    "\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        entity = row[0].strip()\n",
    "\n",
    "        if is_url(entity):\n",
    "            query = f\"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "\n",
    "                SELECT DISTINCT ?type ?title\n",
    "                WHERE {{\n",
    "                    <{entity}> rdf:type ?type .\n",
    "                     \n",
    "                }}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "                SELECT ?type \n",
    "                WHERE {{ \n",
    "                       ?s dcterms:title \"{entity}\" ;\n",
    "                                rdf:type ?type .\n",
    "                                                  }}\n",
    "            \"\"\"\n",
    "\n",
    "        execute_query_and_write_results(entity, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d2dedc4-5a32-4235-87a1-2ec30de2c432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the types.txt file and read the types\n",
    "with open('stypes.txt', 'r') as file:\n",
    "    types = file.readlines()\n",
    "\n",
    "# Use a set to get unique types\n",
    "unique_types = set([type.strip() for type in types])\n",
    "\n",
    "# Write the unique types to types.csv\n",
    "with open('stypes.csv', 'w', newline='') as file:\n",
    "    for type in unique_types:\n",
    "        file.write(type + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e3988-77b7-41e4-9c9d-147fb5c96989",
   "metadata": {},
   "source": [
    "# get types but if the entity is a type return itself and other types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be7276f9-6cac-403c-b6f4-ba2831b6e817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    " \n",
    "sparql_endpoint = \"http://bio2rdf.org/sparql\"\n",
    "\n",
    "sparql = SPARQLWrapper(sparql_endpoint)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "def is_url(string):\n",
    "    url_regex = re.compile(\n",
    "        r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    )\n",
    "    return re.match(url_regex, string) is not None\n",
    "\n",
    "def execute_query_and_write_results(entity, query, is_entity_url):\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        results = sparql.query().convert()\n",
    "        types = set()\n",
    "        has_results = bool(results[\"results\"][\"bindings\"])  # Check if the result set is not empty\n",
    "\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            type_value = result.get(\"type\", {}).get(\"value\")\n",
    "            \n",
    "            if type_value:\n",
    "                if type_value in [\"http://www.w3.org/2002/07/owl#Class\", \"http://www.w3.org/2000/01/rdf-schema#Class\"]:\n",
    "                    types.add(entity)\n",
    "                else:\n",
    "                    types.add(type_value)\n",
    " \n",
    "        if has_results and not is_entity_url:\n",
    "            titles_file.write(entity + '\\n')\n",
    "\n",
    "        for type_value in types:\n",
    "            types_file.write(type_value + '\\n')\n",
    "\n",
    "        if not types:\n",
    "            without_type_file.write(entity + '\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the entity {entity}: {e}\")\n",
    "\n",
    "with open('extracted_entities.csv', mode ='r') as file, \\\n",
    "     open('types1.txt', 'w') as types_file, \\\n",
    "     open('titles1.txt', 'w') as titles_file, \\\n",
    "     open('without_type1.txt', 'w') as without_type_file:\n",
    "\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        entity = row[0].strip()\n",
    "        is_entity_url = is_url(entity)\n",
    "\n",
    "        if is_entity_url:\n",
    "            query = f\"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "\n",
    "                SELECT DISTINCT ?type  \n",
    "                WHERE {{\n",
    "                    <{entity}> rdf:type ?type .\n",
    "                                    }}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "                SELECT ?type \n",
    "                WHERE {{ \n",
    "                       ?s dcterms:title \"{entity}\" ;\n",
    "                                rdf:type ?type .\n",
    "                }}\n",
    "            \"\"\"\n",
    "\n",
    "        execute_query_and_write_results(entity, query, is_entity_url)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b05e3e-bbb8-483d-9201-3b9a20fc0ff4",
   "metadata": {},
   "source": [
    "## query extracted entity againt only bio2rdf graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc9800-c082-4bed-991d-6e945e3d09e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "# Load entities from CSV file\n",
    "entities_df = pd.read_csv('extracted_entities.csv')\n",
    "entities = entities_df.iloc[:, 0].tolist()\n",
    "\n",
    "# Define the Bio2RDF SPARQL endpoint\n",
    "sparql_endpoint = \"http://bio2rdf.org/sparql\"\n",
    "\n",
    "# Define the graphs to query\n",
    "graphs = [\n",
    "\"http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\",\n",
    "\"http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\",\n",
    "\"http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\",\n",
    "\"http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\",\n",
    "\"http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\",\n",
    "\"http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\",\n",
    "\"http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\",\n",
    "\"http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\",\n",
    "\"http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\",\n",
    "\"http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\",\n",
    "\"http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\",\n",
    "\"http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\",\n",
    "\"http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\",\n",
    "\"http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\",\n",
    "\"http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\",\n",
    "\"http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\",\n",
    "\"http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\",\n",
    "\"http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\",\n",
    "\"http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\",\n",
    "\"http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\",\n",
    "\"http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\",\n",
    "\"http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\",\n",
    "\"http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\",\n",
    "\"http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\",\n",
    "\"http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\",\n",
    "\"http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\"]\n",
    "\n",
    "# Initialize SPARQLWrapper\n",
    "sparql = SPARQLWrapper(sparql_endpoint)\n",
    "\n",
    "# Function to format the entity for the SPARQL query\n",
    "def format_entity(entity):\n",
    "    try:\n",
    "        result = urlparse(entity)\n",
    "        if all([result.scheme, result.netloc]):\n",
    "            return f\"<{entity}>\"  # URL\n",
    "    except:\n",
    "        pass\n",
    "    return f\"\\\"{entity}\\\"\"  # Literal\n",
    "\n",
    "# Function to check if an entity exists in a graph\n",
    "def entity_exists_in_graph(entity, graph):\n",
    "    formatted_entity = format_entity(entity)\n",
    "    \n",
    "    # Check as subject\n",
    "    sparql.setQuery(f\"\"\"\n",
    "    ASK WHERE {{\n",
    "        GRAPH <{graph}> {{\n",
    "            {formatted_entity} ?p ?o.\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    exists_as_subject = sparql.query().convert()['boolean']\n",
    "\n",
    "    # Adding a delay to reduce load on the server\n",
    "    # time.sleep(1)  # Delay for 1 second\n",
    "\n",
    "    if exists_as_subject:\n",
    "        return True\n",
    "\n",
    "    # Check as object\n",
    "    sparql.setQuery(f\"\"\"\n",
    "    ASK WHERE {{\n",
    "        GRAPH <{graph}> {{\n",
    "            ?s ?p {formatted_entity}.\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    exists_as_object = sparql.query().convert()['boolean']\n",
    "\n",
    "    # Adding a delay to reduce load on the server\n",
    "    # time.sleep(1)  # Delay for 1 second\n",
    "\n",
    "    return exists_as_object\n",
    "\n",
    "# Check entities and write valid ones to a new CSV file\n",
    "valid_entities = []\n",
    "for entity in entities:\n",
    "    found = False\n",
    "    for graph in graphs:\n",
    "        if entity_exists_in_graph(entity, graph):\n",
    "            valid_entities.append(entity)\n",
    "            found = True\n",
    "            break\n",
    "        # Adding a delay to reduce load on the server\n",
    "        # time.sleep(1)  # Delay for 1 second\n",
    "    if found:\n",
    "        continue\n",
    "\n",
    "# Write valid entities to CSV\n",
    "pd.DataFrame(valid_entities, columns=['Valid Entities']).to_csv('10_10_valid_entities.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a2aa8-92a4-44bd-8a88-574b53a2ac41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    " \n",
    "sparql_endpoint = \"http://bio2rdf.org/sparql\"\n",
    "\n",
    "sparql = SPARQLWrapper(sparql_endpoint)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "graphs = [\n",
    "\"http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\",\n",
    "\"http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\",\n",
    "\"http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\",\n",
    "\"http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\",\n",
    "\"http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\",\n",
    "\"http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\",\n",
    "\"http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\",\n",
    "\"http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\",\n",
    "\"http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\",\n",
    "\"http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\",\n",
    "\"http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\",\n",
    "\"http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\",\n",
    "\"http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\",\n",
    "\"http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\",\n",
    "\"http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\",\n",
    "\"http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\",\n",
    "\"http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\",\n",
    "\"http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\",\n",
    "\"http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\",\n",
    "\"http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\",\n",
    "\"http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\",\n",
    "\"http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\",\n",
    "\"http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\",\n",
    "\"http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\",\n",
    "\"http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\",\n",
    "\"http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\"]\n",
    "\n",
    "def is_url(string):\n",
    "    url_regex = re.compile(\n",
    "        r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    )\n",
    "    return re.match(url_regex, string) is not None\n",
    "\n",
    "def execute_query_and_write_results(entity, queries, is_entity_url):\n",
    "    for query in queries:\n",
    "        try:\n",
    "            sparql.setQuery(query)\n",
    "            results = sparql.query().convert()\n",
    "            types = set()\n",
    "            has_results = bool(results[\"results\"][\"bindings\"])  # Check if the result set is not empty\n",
    "\n",
    "            if has_results:\n",
    "                for result in results[\"results\"][\"bindings\"]:\n",
    "                    type_value = result.get(\"type\", {}).get(\"value\")\n",
    "                    if type_value:\n",
    "                        if type_value in [\"http://www.w3.org/2002/07/owl#Class\", \"http://www.w3.org/2000/01/rdf-schema#Class\"]:\n",
    "                            types.add(entity)\n",
    "                        else:\n",
    "                            types.add(type_value)\n",
    "                break  # Found results, no need to query other graphs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing the entity {entity}: {e}\")\n",
    "\n",
    "    # Write results to files (outside the loop)\n",
    "    if has_results and not is_entity_url:\n",
    "        titles_file.write(entity + '\\n')\n",
    "\n",
    "    for type_value in types:\n",
    "        types_file.write(type_value + '\\n')\n",
    "\n",
    "    if not types:\n",
    "        without_type_file.write(entity + '\\n')\n",
    "\n",
    "with open('extracted_entities.csv', mode='r') as file, \\\n",
    "     open('10_types.txt', 'w') as types_file, \\\n",
    "     open('10_literals.txt', 'w') as titles_file, \\\n",
    "     open('10_without_type.txt', 'w') as without_type_file:\n",
    "\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        entity = row[0].strip()\n",
    "        is_entity_url = is_url(entity)\n",
    "\n",
    "        queries = []\n",
    "        for graph in graphs:\n",
    "            if is_entity_url:\n",
    "                query = f\"\"\"\n",
    "                    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                    PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "\n",
    "                    SELECT DISTINCT ?type  \n",
    "                    FROM <{graph}>\n",
    "                    WHERE {{\n",
    "                        <{entity}> rdf:type ?type .\n",
    "                    }}\n",
    "                \"\"\"\n",
    "            else:\n",
    "                query = f\"\"\"\n",
    "                    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                    PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "                    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "                    SELECT ?type \n",
    "                    FROM <{graph}>\n",
    "                    WHERE {{\n",
    "                        {{\n",
    "                            ?s dcterms:title \"{entity}\" ;\n",
    "                            rdf:type ?type .\n",
    "                        }}\n",
    "                        UNION\n",
    "                        {{\n",
    "                            FILTER NOT EXISTS {{ ?s dcterms:title \"{entity}\" }}\n",
    "                            ?s rdfs:label \"{entity}\" ;\n",
    "                            rdf:type ?type .\n",
    "                        }}\n",
    "                    }}\n",
    "                \"\"\"\n",
    "            queries.append(query)\n",
    "\n",
    "        execute_query_and_write_results(entity, queries, is_entity_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b22af3e-43b7-4201-80a0-0ecb76427659",
   "metadata": {},
   "source": [
    "# get uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54206c73-f98e-4708-8aa8-e5ed3a00f841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the types.txt file and read the types\n",
    "with open('10_types.txt', 'r') as file:\n",
    "    types = file.readlines()\n",
    "\n",
    "# Use a set to get unique types\n",
    "unique_types = set([type.strip() for type in types])\n",
    "\n",
    "# Write the unique types to types.csv\n",
    "with open('10_types.csv', 'w', newline='') as file:\n",
    "    for type in unique_types:\n",
    "        file.write(type + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2d875-46af-4c81-8524-7953c912d6a7",
   "metadata": {},
   "source": [
    "30918 entities reduced to 1030 types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50188061-9824-47d5-a6a7-186e388f331f",
   "metadata": {},
   "source": [
    "# get types labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c207477c-07ba-4186-be39-357ffb313d77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles and labels have been written to type_labels.csv\n"
     ]
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import csv\n",
    "\n",
    "def execute_query(query):\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    titles = [result[\"title\"][\"value\"] for result in results[\"results\"][\"bindings\"]]\n",
    "    return titles\n",
    "\n",
    "# Set up the SPARQL endpoint connection\n",
    "sparql = SPARQLWrapper(\"http://bio2rdf.org/sparql\")  # replace with your SPARQL endpoint\n",
    "\n",
    "# Read types from types.csv\n",
    "types = []\n",
    "with open('types1.csv', mode ='r') as file:\n",
    "    csvReader = csv.reader(file)\n",
    "    types = [row[0] for row in csvReader if row]  # assuming the type is in the first column\n",
    "\n",
    "# Store titles or labels corresponding to types\n",
    "type_titles = {}\n",
    "\n",
    "for type_ in types:\n",
    "    # Replace TYPE_URI with the actual type URI if needed\n",
    "    title_query = f\"\"\"\n",
    "        SELECT ?title WHERE {{\n",
    "            <{type_}> <http://purl.org/dc/terms/title> ?title .\n",
    "        }}\n",
    "    \"\"\"\n",
    "\n",
    "    titles = execute_query(title_query)\n",
    "\n",
    "    if not titles:\n",
    "        label_query = f\"\"\"\n",
    "            SELECT ?title WHERE {{\n",
    "                <{type_}> <http://www.w3.org/2000/01/rdf-schema#label> ?title .\n",
    "            }}\n",
    "        \"\"\"\n",
    "        titles = execute_query(label_query)\n",
    "\n",
    "    type_titles[type_] = titles\n",
    "\n",
    "# Write the titles or labels to type_labels.csv\n",
    "with open('types-test_labels.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Type','Title'])  # Changed this line to only include one column header\n",
    "\n",
    "    for type_,titles in type_titles.items():\n",
    "        if titles:\n",
    "            for title in titles:\n",
    "                writer.writerow([type_,title])  # Removed the type_ as we only want to write titles\n",
    "        else:\n",
    "                writer.writerow([\"no\"])\n",
    "            \n",
    "print(\"Titles and labels have been written to type_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71cf1bf6-f736-48d8-a68d-af1276b8b362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values have been written to u_types1_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the input CSV file\n",
    "input_file = 'types1_labels.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Get the unique rows based on all columns\n",
    "unique_df = df.drop_duplicates()\n",
    "\n",
    "# Write the unique rows to an output CSV file\n",
    "output_file = 'u_types1_labels.csv'\n",
    "unique_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Unique values have been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fee555-0670-47e4-9b52-868ffc61e296",
   "metadata": {},
   "source": [
    "## properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee05bbf-77fa-4f1f-8593-93316084b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# List of graphs\n",
    "graphs = [\n",
    "\"http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\",\n",
    "\"http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\",\n",
    "\"http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\",\n",
    "\"http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\",\n",
    "\"http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\",\n",
    "\"http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\",\n",
    "\"http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\",\n",
    "\"http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\",\n",
    "\"http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\",\n",
    "\"http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\",\n",
    "\"http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\",\n",
    "\"http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\",\n",
    "\"http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\",\n",
    "\"http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\",\n",
    "\"http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\",\n",
    "\"http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\",\n",
    "\"http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\",\n",
    "\"http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\",\n",
    "\"http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\",\n",
    "\"http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\",\n",
    "\"http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\",\n",
    "\"http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\",\n",
    "\"http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\",\n",
    "\"http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\",\n",
    "\"http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\",\n",
    "\"http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\"]\n",
    "\n",
    "# Function to check if predicate exists in a specific graph of Bio2RDF\n",
    "def check_predicate_in_graph(predicate, graph):\n",
    "    sparql = SPARQLWrapper(\"https://bio2rdf.org/sparql\")\n",
    "    query = f\"ASK FROM <{graph}> {{ ?s <{predicate}> ?o }}\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        return results['boolean']\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying predicate {predicate} in graph {graph}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Lists to hold predicates based on existence in Bio2RDF and errors\n",
    "exists = []\n",
    "does_not_exist = []\n",
    "errors = []\n",
    "\n",
    "# Read predicates from CSV file and check their existence in each Bio2RDF graph\n",
    "with open('Logs_properties.csv', mode='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    for predicate in csvFile:\n",
    "        predicate_found = False\n",
    "        for graph in graphs:\n",
    "            result = check_predicate_in_graph(predicate[0], graph)\n",
    "            if result is True:\n",
    "                exists.append(predicate[0])\n",
    "                predicate_found = True\n",
    "                break\n",
    "            elif result is None:\n",
    "                errors.append(predicate[0])\n",
    "                break\n",
    "        if not predicate_found and predicate[0] not in errors:\n",
    "            does_not_exist.append(predicate[0])\n",
    "\n",
    "# Write predicates that exist in Bio2RDF to a file\n",
    "with open('10_Logs_properties.csv', 'w') as file:\n",
    "    for predicate in exists:\n",
    "        file.write(predicate + '\\n')\n",
    "\n",
    "# Write predicates that do not exist in Bio2RDF to a file\n",
    "with open('10_p_not_in_bio2rdf.txt', 'w') as file:\n",
    "    for predicate in does_not_exist:\n",
    "        file.write(predicate + '\\n')\n",
    "\n",
    "# Print or log predicates that caused errors\n",
    "print(\"Predicates that caused errors:\")\n",
    "for predicate in errors:\n",
    "    print(predicate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd9093-6ca3-45c3-ba4f-017129e66c49",
   "metadata": {},
   "source": [
    "# Get Schema vocabularies from KG using queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5503a542-2a1d-4bc2-a972-9aac3993bf6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\n",
      "Query returned 92 results.\n",
      "Query returned 74 results.\n",
      "Processing http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\n",
      "Query returned 11 results.\n",
      "Query returned 51 results.\n",
      "Processing http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\n",
      "Query returned 12 results.\n",
      "Query returned 24 results.\n",
      "Processing http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\n",
      "Query returned 2 results.\n",
      "Query returned 13 results.\n",
      "Processing http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\n",
      "Query returned 5 results.\n",
      "Query returned 35 results.\n",
      "Processing http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\n",
      "Query returned 65 results.\n",
      "Query returned 168 results.\n",
      "Processing http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\n",
      "Query returned 77 results.\n",
      "Query returned 150 results.\n",
      "Processing http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\n",
      "Query returned 68 results.\n",
      "Query returned 85 results.\n",
      "Processing http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\n",
      "Query returned 23 results.\n",
      "Query returned 52 results.\n",
      "Processing http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\n",
      "Query returned 14 results.\n",
      "Query returned 71 results.\n",
      "Processing http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\n",
      "Query returned 40 results.\n",
      "Query returned 103 results.\n",
      "Processing http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\n",
      "Query returned 12 results.\n",
      "Query returned 25 results.\n",
      "Processing http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\n",
      "Query returned 10 results.\n",
      "Query returned 31 results.\n",
      "Processing http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\n",
      "Query returned 27 results.\n",
      "Query returned 40 results.\n",
      "Processing http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\n",
      "Query returned 37 results.\n",
      "Query returned 83 results.\n",
      "Processing http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\n",
      "Query returned 23 results.\n",
      "Query returned 57 results.\n",
      "Processing http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\n",
      "Query returned 103 results.\n",
      "Query returned 113 results.\n",
      "Processing http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\n",
      "Query returned 31 results.\n",
      "Query returned 48 results.\n",
      "Processing http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\n",
      "Query returned 15 results.\n",
      "Query returned 36 results.\n",
      "Processing http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\n",
      "Query returned 18 results.\n",
      "Query returned 37 results.\n",
      "Processing http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\n",
      "Query returned 48 results.\n",
      "Query returned 46 results.\n",
      "Processing http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\n",
      "Query returned 15 results.\n",
      "Query returned 38 results.\n",
      "Processing http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\n",
      "Query returned 45 results.\n",
      "Query returned 83 results.\n",
      "Processing http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\n",
      "Query returned 37 results.\n",
      "Query returned 67 results.\n",
      "Processing http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\n",
      "Query returned 13 results.\n",
      "Query returned 42 results.\n",
      "Processing http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\n",
      "Query returned 84 results.\n",
      "Query returned 47 results.\n",
      "Wrote 601 items to 10_Classes_schema.csv\n",
      "Wrote 1106 items to 10_Predicates_schema.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import csv\n",
    "\n",
    "# List of dataset files\n",
    "dataset_files = [\n",
    "\"http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\",\n",
    "\"http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\",\n",
    "\"http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\",\n",
    "\"http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\",\n",
    "\"http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\",\n",
    "\"http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\",\n",
    "\"http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\",\n",
    "\"http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\",\n",
    "\"http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\",\n",
    "\"http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\",\n",
    "\"http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\",\n",
    "\"http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\",\n",
    "\"http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\",\n",
    "\"http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\",\n",
    "\"http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\",\n",
    "\"http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\",\n",
    "\"http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\",\n",
    "\"http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\",\n",
    "\"http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\",\n",
    "\"http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\",\n",
    "\"http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\",\n",
    "\"http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\",\n",
    "\"http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\",\n",
    "\"http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\",\n",
    "\"http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\",\n",
    "\"http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\"]\n",
    "\n",
    "# Replace `your_sparql_endpoint` with the actual SPARQL endpoint URL\n",
    "sparql_endpoint = \"http://bio2rdf.org/sparql\"\n",
    "def execute_query(sparql_query):\n",
    "    sparql = SPARQLWrapper(sparql_endpoint)\n",
    "    sparql.setQuery(sparql_query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        print(f\"Query returned {len(results['results']['bindings'])} results.\")  # Diagnostic print\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# This will hold all distinct class types and predicates\n",
    "classes_set = set()\n",
    "predicates_set = set()\n",
    "\n",
    "# Function to write results to CSV\n",
    "def write_results_to_csv(file_name, results_set):\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for item in results_set:\n",
    "            writer.writerow([item])\n",
    "        print(f\"Wrote {len(results_set)} items to {file_name}\")  # Diagnostic print\n",
    "\n",
    "# Loop through dataset files to construct the schema\n",
    "for file_url in dataset_files:\n",
    "    # dataset_uri = extract_dataset_uri(file_url)\n",
    "    # if dataset_uri:\n",
    "        print(f\"Processing {file_url}\")\n",
    "        # Query to find all distinct types\n",
    "        query_types = f\"\"\"\n",
    "        SELECT DISTINCT ?type\n",
    "        FROM <{file_url}>\n",
    "        WHERE {{ ?s a ?type }}\n",
    "        \"\"\"\n",
    "        results_types = execute_query(query_types)\n",
    "        for result in results_types[\"results\"][\"bindings\"]:\n",
    "            classes_set.add(result[\"type\"][\"value\"])\n",
    "        \n",
    "        # Query to find all distinct predicates\n",
    "        query_predicates = f\"\"\"\n",
    "        SELECT DISTINCT ?p\n",
    "        FROM <{file_url}>\n",
    "        WHERE {{ ?s ?p ?o }}\n",
    "        \"\"\"\n",
    "        results_predicates = execute_query(query_predicates)\n",
    "        for result in results_predicates[\"results\"][\"bindings\"]:\n",
    "            predicates_set.add(result[\"p\"][\"value\"])\n",
    "        \n",
    "# Write the results to CSV files\n",
    "write_results_to_csv('10_Classes_schema.csv', classes_set)\n",
    "write_results_to_csv('10_Predicates_schema.csv', predicates_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610c57e-de25-4ce1-baaf-38efc5cb98f8",
   "metadata": {},
   "source": [
    "# Get superclasses as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b52c1532-53ac-4fea-8876-4b21b7d2b3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Initialize the SPARQL wrapper with the endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://bio2rdf.org/sparql\")\n",
    "\n",
    "# Function to get the superclass of a given class\n",
    "def get_superclass(class_uri):\n",
    "    query = \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?superclass\n",
    "    WHERE {\n",
    "      <\"\"\" + class_uri + \"\"\"> rdfs:subClassOf ?superclass .\n",
    "    }\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    # Extract the superclass URIs from the query results\n",
    "    superclasses = [result['superclass']['value'] for result in results[\"results\"][\"bindings\"]]\n",
    "    # print(\"s\")\n",
    "    # print(\"superclasses\", superclasses)\n",
    "    return superclasses\n",
    "\n",
    "# Read the classes from the CSV file\n",
    "classes_df = pd.read_csv('10_superclasses.csv')\n",
    "\n",
    "# This assumes that the first column contains the class URIs\n",
    "class_uris = classes_df.iloc[:, 0].unique()\n",
    "\n",
    "# Get the superclasses for each class URI\n",
    "superclasses_list = []\n",
    "for class_uri in class_uris:\n",
    "    superclasses = get_superclass(class_uri)\n",
    "    superclasses_list.extend(superclasses)\n",
    "\n",
    "# Remove duplicates and write to CSV\n",
    "superclasses_df = pd.DataFrame(list(set(superclasses_list)), columns=['Superclass'])\n",
    "superclasses_df.to_csv('10_sup_superclasses.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb80a9-167a-424e-a1a4-c9c13dc37776",
   "metadata": {},
   "source": [
    "# Get subclasses as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3cadc-21b9-43ec-b737-cf3f73281467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74981ad6-3233-40d9-94f4-f905eae2f02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "superclasses ['http://bio2rdf.org/wormbase_vocabulary:Change_of_expression_level-Regulatory-Interaction', 'http://bio2rdf.org/wormbase_vocabulary:Regulatory-Interaction', 'http://bio2rdf.org/wormbase_vocabulary:Change_of_localization-Regulatory-Interaction']\n",
      "s\n",
      "superclasses []\n",
      "s\n",
      "superclasses []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Initialize the SPARQL wrapper with the endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://bio2rdf.org/sparql\")\n",
    "\n",
    "# Function to get the superclass of a given class\n",
    "def get_superclass(class_uri):\n",
    "    query = \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?subclass\n",
    "    WHERE {\n",
    "      ?subclass rdfs:subClassOf <\"\"\" + class_uri + \"\"\"> .\n",
    "    }\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    # Extract the superclass URIs from the query results\n",
    "    superclasses = [result['subclass']['value'] for result in results[\"results\"][\"bindings\"]]\n",
    "    # print(\"s\")\n",
    "    # print(\"superclasses\", superclasses)\n",
    "    return superclasses\n",
    "\n",
    "# Read the classes from the CSV file\n",
    "classes_df = pd.read_csv('10_subclass.csv')\n",
    "\n",
    "# This assumes that the first column contains the class URIs\n",
    "class_uris = classes_df.iloc[:, 0].unique()\n",
    "\n",
    "# Get the superclasses for each class URI\n",
    "superclasses_list = []\n",
    "for class_uri in class_uris:\n",
    "    superclasses = get_superclass(class_uri)\n",
    "    superclasses_list.extend(superclasses)\n",
    "\n",
    "# Remove duplicates and write to CSV\n",
    "superclasses_df = pd.DataFrame(list(set(superclasses_list)), columns=['Superclass'])\n",
    "superclasses_df.to_csv('10_sub_subclass.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed59553-2d79-4508-9f18-87221ad37ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    " ##  clean schema classes [KG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "69619d7a-23e2-4f39-b633-bb89d94dd085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows have been written to 10_bio2rdf_spesific_Classes_schema.csv as per the conditions.\n",
      "count is: 527\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the input and output filenames\n",
    "input_filename = '10_Classes_schema.csv'\n",
    "output_filename = '10_bio2rdf_spesific_Classes_schema.csv'\n",
    "count = 0\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_filename, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "        open(output_filename, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "    # Create reader and writer objects\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Iterate over each row in the input CSV\n",
    "    for row in reader:\n",
    "        # Check each cell in the row\n",
    "        for value in row:\n",
    "            # If the cell contains '_vocabulary' or contains 'http:' without ':', write the row to the output CSV\n",
    "#             or ('http:' in value and ':' not in value.replace('http:', ''))\n",
    "            if '_vocabulary' in value :\n",
    "                writer.writerow(row)\n",
    "                count = count + 1\n",
    "                break  # We write the row once if it meets the condition and then move to the next row\n",
    "\n",
    "print(f\"Rows have been written to {output_filename} as per the conditions.\")\n",
    "print(\"count is:\", count )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461c415f-9fd6-4088-a70d-96f858baf1c9",
   "metadata": {
    "tags": []
   },
   "source": [
    " ##  clean types extracted from queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a15c247b-7c88-40d9-9db4-41227d9cea1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows have been written to types_not_domain.csv as per the conditions.\n",
      "count is: 79\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the input and output filenames\n",
    "input_filename = 'types1.csv'\n",
    "output_filename = 'types_not_domain.csv'\n",
    "count = 0\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_filename, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "        open(output_filename, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "    # Create reader and writer objects\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Iterate over each row in the input CSV\n",
    "    for row in reader:\n",
    "        # Check each cell in the row\n",
    "        for value in row:\n",
    "            # If the cell contains '_vocabulary' or contains 'http:' without ':', write the row to the output CSV\n",
    "#             or ('http:' in value and ':' not in value.replace('http:', ''))\n",
    "            if '_vocabulary' not in value and ('http:' in value and ':' not in value.replace('http:', '')):\n",
    "                writer.writerow(row)\n",
    "                count = count + 1\n",
    "                break  # We write the row once if it meets the condition and then move to the next row\n",
    "\n",
    "print(f\"Rows have been written to {output_filename} as per the conditions.\")\n",
    "print(\"count is:\", count )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41640bee-f3bb-4718-8b4e-b3ef1c6ff7c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## get the entities that are in kg schema but not in queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf9707-0d97-419b-9a57-f4eb98247e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"10_bio2rdf_total_schema_elements.txt\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open(\"types20.csv\", \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 3: Write the existing entities to `EntitiesInQueriesExist_in_KG_schema.csv`\n",
    "with open(\"typesInQueriesExist_in_KG_schema.csv\", \"w\", newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    for entity in entities_in_kg:\n",
    "        csv_writer.writerow([entity])\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of entities in queries that exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d41090-62f9-47f9-9c0e-a9586bfa5804",
   "metadata": {},
   "source": [
    "\n",
    "## get the entities that are in queries but not in kg schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae001680-a3d5-4ebf-a6eb-8ea5533ff1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities in queries that not exist in KG schema: 4\n",
      "\n",
      "Entities that don't exist in KG schema:\n",
      "http://bio2rdf.org/hgnc_vocabulary:Status\n",
      "http://bio2rdf.org/drugbank_vocabulary:7cab3885cdbcb9df8c405e9c9ad10732\n",
      "http://bio2rdf.org/hgnc_vocabulary:Approved\n",
      "http://bio2rdf.org/atmo_vocabulary:Resource\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"types20.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open( \"10_sup_bio2rdf_spesific_Classes_schema.csv\" , \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 3: Write the existing entities to `EntitiesInQueriesExist_in_KG_schema.csv`\n",
    "with open(\"queries_types_valid_KG_schema.csv\", \"w\", newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    for entity in entities_in_kg:\n",
    "        csv_writer.writerow([entity])\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of entities in queries that not exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d29262-5392-4158-9443-8053e26c4e6b",
   "metadata": {},
   "source": [
    "## we delet http://bio2rdf.org/atmo_vocabulary:Resource \n",
    "because it is not in schema, it's not bio2rdf vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a9954-f749-4931-946e-1592ffc4f3c0",
   "metadata": {},
   "source": [
    " ##  clean properties extracted from queries [Logs_properties.csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546f287a-6681-4c67-93c4-3aca488a992e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of properties in queries that not exist in KG schema: 198\n",
      "\n",
      " properties that don't exist in KG schema:\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftXmlIndex\n",
      "http://purl.org/goodrelations/v1#includes\n",
      "http://www.w3.org/ns/dcat#downloadURL\n",
      "http://semanticscience.org/resource/SIO_000205\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSuperFormats\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCmpFuncName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcAlias\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfMapsOnlyNullToNull\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsMatchingFlags\n",
      "http://www.w3.org/ns/dcat#theme\n",
      "http://www.w3.org/2000/01/rdf-schema#domain\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIidOfShortTmpl\n",
      "http://purl.org/dc/terms/accrualPeriodicity\n",
      "http://purl.org/dc/terms/hasPart\n",
      "http://rdfs.org/ns/void#propertyPartition\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000008\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_5\n",
      "http://rdfs.org/ns/void#exampleResource\n",
      "http://rdfs.org/ns/void#vocabulary\n",
      "http://www.w3.org/ns/sparql-service-description#feature\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfStrsqlvalOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrLanguage\n",
      "http://www.bigdata.com/rdf#/features/KB/Namespace\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_2\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftColumnName\n",
      "http://purl.org/ontology/wi/core#evidence\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfName\n",
      "http://xmlns.com/foaf/0.1/logo\n",
      "http://www.w3.org/2000/01/rdf-schema#type\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfUriTmpl\n",
      "http://purl.org/goodrelations/v1#acceptedPaymentMethods\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmPredicateMap\n",
      "http://purl.org/pav/retrievedFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDtpOfNiceSqlval\n",
      "http://semanticscience.org/resource/SIO_010078\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFText\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftAlias\n",
      "http://rdfs.org/ns/void#subjectsTarget\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenEqToSql\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfTypedsqlvalTmpl\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_4\n",
      "http://purl.org/dc/terms/extent\n",
      "http://www.openlinksw.com/schemas/virtrdf#inheritFrom\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_3\n",
      "http://www.openlinksw.com/schemas/virtrdf#item\n",
      "http://rdfs.org/ns/void#sparqlEndpoint\n",
      "http://www.w3.org/2002/07/owl#complementOf\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1\n",
      "http://semanticscience.org/resource/SIO_000341\n",
      "http://www.w3.org/2000/01/rdf-schema#range\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsuriOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsBijection\n",
      "http://purl.org/pav/createdWith\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#TEL\n",
      "http://xmlns.com/foaf/0.1/maker\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmTableName\n",
      "http://purl.org/goodrelations/v1#hasPriceSpecification\n",
      "http://rdfs.org/ns/void#properties\n",
      "http://purl.org/pav/authoredOn\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsUserMaps\n",
      "http://purl.org/goodrelations/v1#validFrom\n",
      "http://www.w3.org/2000/01/rdf-schema#isDescribedUsing\n",
      "http://rdfs.org/ns/void#uriSpace\n",
      "http://purl.org/goodrelations/v1#amountOfThisGood\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Street\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#ADR\n",
      "http://purl.org/dc/terms/conformsTo\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFormat\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfLongTmpl\n",
      "http://rdfs.org/ns/void#distinctSubjects\n",
      "http://www.w3.org/ns/sparql-service-description#endpoint\n",
      "http://www.openlinksw.com/schemas/virtrdf#isSpecialPredicate\n",
      "http://purl.org/dc/terms/references\n",
      "http://purl.org/pav/importedOn\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolOfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000772\n",
      "http://www.w3.org/ns/sparql-service-description#defaultDataset\n",
      "http://purl.org/goodrelations/v1#validThrough\n",
      "http://purl.org/goodrelations/v1#hasBusinessFunction\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsrefOfShortTmpl\n",
      "http://purl.org/dc/terms/issued\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypemaxTmpl\n",
      "http://semanticscience.org/resource/SIO_000062\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalOfShortTmpl\n",
      "http://purl.uniprot.org/core/organism\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsnumericOfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000095\n",
      "http://semanticscience.org/resource/SIO_000300\n",
      "http://purl.org/dc/terms/createdBy\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIslitOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsStable\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfSqlvalTmpl\n",
      "http://purl.org/goodrelations/v1#BusinessEntity\n",
      "http://www.w3.org/2004/02/skos/core#exactMatch\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfLongTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#loadAs\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfColumnCount\n",
      "http://purl.org/goodrelations/v1#availableAtOrFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumns\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageOfShortTmpl\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#City\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaAlias\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfWrapDistinct\n",
      "http://purl.org/goodrelations/v1#hasUnitOfMeasurement\n",
      "http://www.openlinksw.com/schemas/virtrdf#noInherit\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01uriOfShortTmpl\n",
      "http://purl.org/dc/terms/language\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsblankOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongTmpl\n",
      "http://rdfs.org/ns/void#linkPredicate\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect\n",
      "http://purl.org/dc/terms/isVersionOf\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmMatchingFlags\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#EMAIL\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmGraphMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenRef\n",
      "http://semanticscience.org/resource/SIO_000628\n",
      "http://www.w3.org/ns/sparql-service-description#defaultGraph\n",
      "http://purl.org/goodrelations/v1#availableDeliveryMethods\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvATables\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCustomString1\n",
      "http://purl.org/pav/authoredBy\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmObjectMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcColumnName\n",
      "http://purl.org/pav/version\n",
      "http://rdfs.org/ns/void#objectsTarget\n",
      "http://rdfs.org/ns/void#entities\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmSubjectMap\n",
      "http://purl.org/pav/createdBy\n",
      "http://semanticscience.org/resource/SIO_000253\n",
      "http://purl.org/goodrelations/v1#includesObject\n",
      "http://purl.org/goodrelations/v1#eligibleRegions\n",
      "http://purl.org/goodrelations/v1#legalName\n",
      "http://purl.org/goodrelations/v1#eligibleCustomerTypes\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Pcode\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfTypedsqlvalTmpl\n",
      "http://www.w3.org/2002/07/owl#versionInfo\n",
      "http://rdfs.org/ns/void#classPartition\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01blankOfShortTmpl\n",
      "http://purl.org/dc/terms/rightsHolder\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrDatatype\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfUriTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrRestrictions\n",
      "http://purl.org/pav/2.0/version\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfUriOfShortTmpl\n",
      "http://rdfs.org/ns/void#class\n",
      "http://purl.org/pav/lastUpdateOn\n",
      "http://www.w3.org/ns/sparql-service-description#supportedLanguage\n",
      "http://www.w3.org/ns/sparql-service-description#url\n",
      "http://rdfs.org/ns/void#triples\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLong\n",
      "http://xmlns.com/foaf/0.1/homepage\n",
      "http://xmlns.com/foaf/0.1/mbox\n",
      "http://www.openlinksw.com/schemas/virtrdf#version\n",
      "http://rdfs.org/ns/void#property\n",
      "http://purl.org/goodrelations/v1#offers\n",
      "http://www.openlinksw.com/schemas/DAV#ownerUser\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvGeo\n",
      "http://www.w3.org/ns/sparql-service-description#resultFormat\n",
      "http://www.w3.org/2002/07/owl#priorVersion\n",
      "http://semanticscience.org/resource/SIO_000001\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeTmpl\n",
      "http://purl.org/pav/createdOn\n",
      "http://xmlns.com/foaf/0.1/primaryTopic\n",
      "http://www.openlinksw.com/schemas/virtrdf#catName\n",
      "http://rdfs.org/ns/void#classes\n",
      "http://www.w3.org/ns/prov#wasDerivedFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfOkForAnySqlvalue\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#isGcResistantType\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Country\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsDefaultMap\n",
      "http://rdfs.org/ns/void#distinctObjects\n",
      "http://semanticscience.org/resource/SIO_000216\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumnsFormKey\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypeminTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#inputFormat\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftConds\n",
      "http://www.w3.org/2004/02/skos/core#closeMatch\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfHasCheapSqlval\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfNiceSqlvalTmpl\n",
      "http://purl.org/goodrelations/v1#typeOfGood\n",
      "http://rdfs.org/ns/void#subset\n",
      "http://xmlns.com/foaf/0.1/name\n",
      "http://www.w3.org/ns/dcat#byteSize\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSubFormatForRefs\n",
      "http://purl.org/dc/terms/modified\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"Logs_properties.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open( \"10_Predicates_schema.csv\" , \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 3: Write the existing entities to `EntitiesInQueriesExist_in_KG_schema.csv`\n",
    "with open(\"queries_valid_properties_KG_schema.csv\", \"w\", newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    for entity in entities_in_kg:\n",
    "        csv_writer.writerow([entity])\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of properties in queries that not exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "\n",
    "print(\"\\n properties that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284b262-99c8-44d2-b5f6-02e9e6e93281",
   "metadata": {},
   "source": [
    "# Get total schema element of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1e94e7-d58a-4613-8b61-c6280fcd7770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606 unique elements have been written to unique_elements.txt\n"
     ]
    }
   ],
   "source": [
    "# Set to hold the unique elements from both files\n",
    "unique_elements = set()\n",
    "\n",
    "# Read the property_types.txt file and add its contents to the set\n",
    "with open('queries_valid_properties_KG_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())  # strip() removes any leading/trailing whitespace including newline characters\n",
    "\n",
    "# Read the types1.csv file and add its contents to the set\n",
    "with open('queries_types_valid_KG_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())\n",
    "\n",
    "# Write the unique elements to a new file\n",
    "with open('Logs_total_schema_elements.txt', 'w') as file:\n",
    "    for element in unique_elements:\n",
    "        file.write(element + '\\n')\n",
    "\n",
    "print(f\"{len(unique_elements)} unique elements have been written to unique_elements.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935925b4-3c7d-4d22-b405-26d5dca9bc5d",
   "metadata": {},
   "source": [
    "# Get total schema element count of bio2rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba517f93-25a4-4c7a-b186-6b327dd711ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635 unique elements have been written to unique_elements.txt\n"
     ]
    }
   ],
   "source": [
    "# Set to hold the unique elements from both files\n",
    "unique_elements = set()\n",
    "\n",
    "# Read the property_types.txt file and add its contents to the set\n",
    "with open('10_sup_bio2rdf_spesific_Classes_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())  # strip() removes any leading/trailing whitespace including newline characters\n",
    "\n",
    "# Read the types1.csv file and add its contents to the set\n",
    "with open('10_Predicates_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())\n",
    "\n",
    "# Write the unique elements to a new file\n",
    "with open('10_bio2rdf_total_schema_elements.txt', 'w') as file:\n",
    "    for element in unique_elements:\n",
    "        file.write(element + '\\n')\n",
    "\n",
    "print(f\"{len(unique_elements)} unique elements have been written to unique_elements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550ec66d-da33-4425-ab77-352d491a61d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities in queries that exist in KG schema: 202\n",
      "\n",
      "Entities that don't exist in KG schema:\n",
      "http://rdfs.org/ns/void#subjectsTarget\n",
      "http://rdfs.org/ns/void#property\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFormat\n",
      "http://purl.org/dc/terms/modified\n",
      "http://www.w3.org/2002/07/owl#priorVersion\n",
      "http://purl.org/dc/terms/hasPart\n",
      "http://bio2rdf.org/hgnc_vocabulary:Approved\n",
      "http://www.bigdata.com/rdf#/features/KB/Namespace\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfUriOfShortTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#resultFormat\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfUriTmpl\n",
      "http://purl.org/goodrelations/v1#legalName\n",
      "http://purl.org/goodrelations/v1#availableDeliveryMethods\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfColumnCount\n",
      "http://rdfs.org/ns/void#classes\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsBijection\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_4\n",
      "http://purl.org/ontology/wi/core#evidence\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfTypedsqlvalTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#defaultDataset\n",
      "http://www.w3.org/2000/01/rdf-schema#isDescribedUsing\n",
      "http://purl.org/pav/authoredBy\n",
      "http://purl.org/goodrelations/v1#BusinessEntity\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfOkForAnySqlvalue\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsuriOfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000008\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFText\n",
      "http://rdfs.org/ns/void#exampleResource\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenRef\n",
      "http://www.openlinksw.com/schemas/virtrdf#isGcResistantType\n",
      "http://rdfs.org/ns/void#classPartition\n",
      "http://www.w3.org/ns/dcat#theme\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIslitOfShortTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#supportedLanguage\n",
      "http://semanticscience.org/resource/SIO_000300\n",
      "http://purl.org/goodrelations/v1#typeOfGood\n",
      "http://rdfs.org/ns/void#objectsTarget\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsnumericOfShortTmpl\n",
      "http://purl.org/goodrelations/v1#eligibleCustomerTypes\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmTableName\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1\n",
      "http://www.w3.org/2004/02/skos/core#exactMatch\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCmpFuncName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrDatatype\n",
      "http://www.w3.org/2000/01/rdf-schema#domain\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftColumnName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftConds\n",
      "http://www.openlinksw.com/schemas/virtrdf#loadAs\n",
      "http://www.openlinksw.com/schemas/virtrdf#catName\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#TEL\n",
      "http://purl.org/goodrelations/v1#availableAtOrFrom\n",
      "http://xmlns.com/foaf/0.1/maker\n",
      "http://xmlns.com/foaf/0.1/logo\n",
      "http://purl.org/dc/terms/accrualPeriodicity\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmSubjectMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSuperFormats\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalTmpl\n",
      "http://www.w3.org/2004/02/skos/core#closeMatch\n",
      "http://www.w3.org/ns/sparql-service-description#url\n",
      "http://rdfs.org/ns/void#distinctObjects\n",
      "http://rdfs.org/ns/void#properties\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLong\n",
      "http://xmlns.com/foaf/0.1/mbox\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsblankOfShortTmpl\n",
      "http://www.w3.org/2002/07/owl#versionInfo\n",
      "http://rdfs.org/ns/void#vocabulary\n",
      "http://purl.org/dc/terms/issued\n",
      "http://www.w3.org/ns/sparql-service-description#feature\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmPredicateMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfMapsOnlyNullToNull\n",
      "http://bio2rdf.org/drugbank_vocabulary:7cab3885cdbcb9df8c405e9c9ad10732\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfWrapDistinct\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfUriTmpl\n",
      "http://purl.org/pav/2.0/version\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftAlias\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_5\n",
      "http://semanticscience.org/resource/SIO_000628\n",
      "http://bio2rdf.org/hgnc_vocabulary:Status\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#EMAIL\n",
      "http://www.w3.org/2000/01/rdf-schema#type\n",
      "http://www.openlinksw.com/schemas/virtrdf#item\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcColumnName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrLanguage\n",
      "http://purl.org/pav/createdBy\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrRestrictions\n",
      "http://purl.org/pav/version\n",
      "http://www.openlinksw.com/schemas/virtrdf#noInherit\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsMatchingFlags\n",
      "http://purl.org/goodrelations/v1#eligibleRegions\n",
      "http://purl.org/dc/terms/language\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSubFormatForRefs\n",
      "http://xmlns.com/foaf/0.1/name\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypemaxTmpl\n",
      "http://purl.uniprot.org/core/organism\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmGraphMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#version\n",
      "http://www.openlinksw.com/schemas/DAV#ownerUser\n",
      "http://bio2rdf.org/atmo_vocabulary:Resource\n",
      "http://purl.org/goodrelations/v1#acceptedPaymentMethods\n",
      "http://semanticscience.org/resource/SIO_000062\n",
      "http://purl.org/pav/authoredOn\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvTmpl\n",
      "http://purl.org/pav/importedOn\n",
      "http://purl.org/goodrelations/v1#includesObject\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvATables\n",
      "http://purl.org/dc/terms/isVersionOf\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeTmpl\n",
      "http://www.w3.org/ns/prov#wasDerivedFrom\n",
      "http://purl.org/goodrelations/v1#hasUnitOfMeasurement\n",
      "http://purl.org/goodrelations/v1#includes\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenEqToSql\n",
      "http://purl.org/pav/createdWith\n",
      "http://xmlns.com/foaf/0.1/primaryTopic\n",
      "http://purl.org/pav/retrievedFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfStrsqlvalOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftXmlIndex\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Street\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Country\n",
      "http://rdfs.org/ns/void#triples\n",
      "http://purl.org/goodrelations/v1#hasBusinessFunction\n",
      "http://semanticscience.org/resource/SIO_000216\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypeminTmpl\n",
      "http://purl.org/goodrelations/v1#amountOfThisGood\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCustomString1\n",
      "http://www.openlinksw.com/schemas/virtrdf#inheritFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfNiceSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDtpOfNiceSqlval\n",
      "http://www.w3.org/2000/01/rdf-schema#range\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcAlias\n",
      "http://purl.org/goodrelations/v1#validFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvOfShortTmpl\n",
      "http://purl.org/dc/terms/extent\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumnsFormKey\n",
      "http://semanticscience.org/resource/SIO_000095\n",
      "http://www.w3.org/ns/dcat#downloadURL\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmObjectMap\n",
      "http://purl.org/dc/terms/conformsTo\n",
      "http://www.w3.org/ns/sparql-service-description#inputFormat\n",
      "http://semanticscience.org/resource/SIO_000205\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfLongTmpl\n",
      "http://rdfs.org/ns/void#sparqlEndpoint\n",
      "http://semanticscience.org/resource/SIO_000253\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfHasCheapSqlval\n",
      "http://purl.org/dc/terms/references\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsStable\n",
      "http://www.w3.org/ns/sparql-service-description#defaultGraph\n",
      "http://www.w3.org/ns/dcat#byteSize\n",
      "http://rdfs.org/ns/void#propertyPartition\n",
      "http://semanticscience.org/resource/SIO_000001\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfLongTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01uriOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIidOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvGeo\n",
      "http://www.w3.org/2002/07/owl#complementOf\n",
      "http://xmlns.com/foaf/0.1/homepage\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongOfShortTmpl\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#ADR\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageOfShortTmpl\n",
      "http://rdfs.org/ns/void#linkPredicate\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsrefOfShortTmpl\n",
      "http://rdfs.org/ns/void#class\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfSqlvalTmpl\n",
      "http://purl.org/dc/terms/rightsHolder\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#City\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01blankOfShortTmpl\n",
      "http://purl.org/pav/lastUpdateOn\n",
      "http://purl.org/dc/terms/createdBy\n",
      "http://semanticscience.org/resource/SIO_000341\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_3\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumns\n",
      "http://semanticscience.org/resource/SIO_000772\n",
      "http://purl.org/goodrelations/v1#offers\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsDefaultMap\n",
      "http://rdfs.org/ns/void#distinctSubjects\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmMatchingFlags\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Pcode\n",
      "http://rdfs.org/ns/void#entities\n",
      "http://www.openlinksw.com/schemas/virtrdf#isSpecialPredicate\n",
      "http://www.w3.org/ns/sparql-service-description#endpoint\n",
      "http://rdfs.org/ns/void#uriSpace\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfTypedsqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsUserMaps\n",
      "http://semanticscience.org/resource/SIO_010078\n",
      "http://purl.org/pav/createdOn\n",
      "http://purl.org/goodrelations/v1#hasPriceSpecification\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_2\n",
      "http://rdfs.org/ns/void#subset\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaAlias\n",
      "http://purl.org/goodrelations/v1#validThrough\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"Logs_total_schema_elements.txt\" , \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader] # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open( \"10_bio2rdf_total_schema_elements.txt\"  , \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of entities in queries that exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c726546f-6c97-41ad-8acb-e84f0ce189ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities not in KG schema: 54\n",
      "\n",
      "Entities that don't exist in KG schema:\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:limitations-and-caveats\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:ci-upper-limit\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:lower-limit\n",
      "http://bio2rdf.org/obo_vocabulary:Entity\n",
      "http://bio2rdf.org/kegg_vocabulary:Reversible-Reaction\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:ci-upper-limit-na-comment\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:upper-limit\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:ci-lower-limit\n",
      "http://bio2rdf.org/kegg_vocabulary:Irreversible-Reaction\n",
      "http://bio2rdf.org/broad-lincrna_vocabulary:Resource\n",
      "http://bio2rdf.org/ed_vocabulary:Resource\n",
      "http://bio2rdf.org/ligandbox_vocabulary:Resource\n",
      "http://bio2rdf.org/ncbi-proteinid_vocabulary:Resource\n",
      "http://bio2rdf.org/solgenomics_vocabulary:Resource\n",
      "http://bio2rdf.org/luo_lincrna_vocabulary:Resource\n",
      "http://bio2rdf.org/signalp_vocabulary:Resource\n",
      "http://bio2rdf.org/utoronto_vocabulary:Resource\n",
      "http://bio2rdf.org/v_vocabulary:Resource\n",
      "http://bio2rdf.org/rnacentral_vocabulary:Resource\n",
      "http://bio2rdf.org/phi_vocabulary:Resource\n",
      "http://bio2rdf.org/jcggdb_vocabulary:Resource\n",
      "http://bio2rdf.org/phobius_vocabulary:Resource\n",
      "http://bio2rdf.org/imga_vocabulary:Resource\n",
      "http://bio2rdf.org/id_vocabulary:Resource\n",
      "http://bio2rdf.org/tmhmm_vocabulary:Resource\n",
      "http://bio2rdf.org/ucsc_genes_vocabulary:Resource\n",
      "http://bio2rdf.org/mwsh_vocabulary:Resource\n",
      "http://bio2rdf.org/epcc_vocabulary:Resource\n",
      "http://bio2rdf.org/goc_vocabulary:Resource\n",
      "http://bio2rdf.org/goeco_vocabulary:Resource\n",
      "http://ldf.fi/void-ext#subjectPartition\n",
      "http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#expresses\n",
      "http://www.w3.org/ns/sparql-service-description#namedGraph\n",
      "http://vocabularies.bridgedb.org/ops#objectsDatatype\n",
      "http://vocabularies.bridgedb.org/ops#linksetJustification\n",
      "http://xmlns.com/foaf/0.1/primaryTopicOf\n",
      "http://www.w3.org/ns/dcat#landingPage\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfUriIdOffset\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect-exceptions\n",
      "http://www.w3.org/ns/sparql-service-description#name\n",
      "http://ldf.fi/void-ext#datatype\n",
      "http://www.w3.org/ns/prov#wasGeneratedBy\n",
      "http://xmlns.com/foaf/0.1/member\n",
      "http://www.openlinksw.com/schemas/virtrdf#bestRequestMethod\n",
      "http://rdfs.org/ns/void#datadump\n",
      "http://www.w3.org/ns/sparql-service-description#graph\n",
      "http://www.w3.org/ns/dcat#accessURL\n",
      "http://ldf.fi/void-ext#subject\n",
      "http://vocabularies.bridgedb.org/ops#subjectsDatatype\n",
      "http://ldf.fi/void-ext#datatypePartition\n",
      "http://purl.org/pav/previousVersion\n",
      "http://vocabularies.bridgedb.org/ops#assertionMethod\n",
      "http://schema.org/logo\n",
      "http://rdfs.org/ns/void#dataDump\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Read entities from `bio2rdf_total_schema_elements.txt`\n",
    "with open(\"bio2rdf_total_schema_elements.txt\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Check if they exist in `Logs_total_schema_elements.txt`\n",
    "with open(\"Logs_total_schema_elements.txt\", \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "# Determine which entities are not in the knowledge graph\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "# We will sort the entities based on whether they contain '_vocabulary:Resource' or '_vocabulary'\n",
    "resource_entities = [entity for entity in entities_not_in_kg if '_vocabulary:Resource' in entity]\n",
    "vocabulary_entities = [entity for entity in entities_not_in_kg if '_vocabulary' in entity and entity not in resource_entities]\n",
    "other_entities = [entity for entity in entities_not_in_kg if entity not in resource_entities and entity not in vocabulary_entities]\n",
    "\n",
    "# Now we combine the lists, keeping the desired order\n",
    "sorted_entities_not_in_kg = vocabulary_entities + resource_entities + other_entities\n",
    "\n",
    "print(f\"Count of entities not in KG schema: {len(sorted_entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in sorted_entities_not_in_kg:\n",
    "    print(entity)\n",
    "# 10_Subclass_all.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33779f3d-98bf-49fb-b675-01e149dd64e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities not in KG schema: 0\n",
      "\n",
      "Entities that don't exist in KG schema:\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Read entities from `10_Subclass_all.csv`\n",
    "entities = []\n",
    "with open(\"10_Subclass_all.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        if row:  # Check if row is not empty\n",
    "            entities.append(row[0])  # Assuming the entity is in the first column\n",
    "\n",
    "# Check if they exist in `10_bio2rdf_total_schema_elements.txt`\n",
    "with open(\"10_bio2rdf_total_schema_elements.txt\", \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "# Determine which entities are not in the knowledge graph\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "print(f\"Count of entities not in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54638dd3-c462-49da-99a9-611cd52569b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
