{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37fa619d-8402-4815-b6df-cfd313952c2a",
   "metadata": {},
   "source": [
    "# Code for Hackathon: Schema coverage calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Method:\n",
    "\n",
    "- get unique queries (does not handle the white spaces)\n",
    "- parse queries\n",
    "- get normalized queries\n",
    "- get unique queries from normalized verion and parsed tree(to handle white space problem)\n",
    "- get triples from queries\n",
    "- get schema elements from triple pattern\n",
    "- get schema elements from Knowledge graph\n",
    "- schema coverage calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. We download the query logs from \"link to download the logs\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value counts:\n",
      "query    0\n",
      "dtype: int64\n",
      "16\n",
      "                                                                                                                                  query\n",
      "0                                                                                                  SELECT * WHERE { ?s ?p ?o } LIMIT 10\n",
      "1                SELECT ?drug ?label WHERE { ?drug a <http://bio2rdf.org/drugbank_vocabulary:Drug> . ?drug rdfs:label ?label } LIMIT 10\n",
      "2  SELECT ?gene ?description WHERE { ?gene a <http://bio2rdf.org/gene_vocabulary:Gene> . ?gene rdfs:description ?description } LIMIT 10\n",
      "3           SELECT ?disease ?name WHERE { ?disease a <http://bio2rdf.org/omim_vocabulary:Disease> . ?disease rdfs:name ?name } LIMIT 10\n",
      "4        CONSTRUCT { ?s a <http://bio2rdf.org/gene_vocabulary:Gene> } WHERE { ?s a <http://bio2rdf.org/gene_vocabulary:Gene> } LIMIT 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('bio2rdf_sparql_queries.csv', lineterminator='\\n', dtype=str, encoding='utf-8')\n",
    "\n",
    "# Count the number of null values in each column\n",
    "null_counts = df.isnull().sum()\n",
    "\n",
    "print(\"Null value counts:\")\n",
    "print(null_counts)\n",
    "print(len(df))\n",
    "pd.set_option('display.max_colwidth', None)  # Display full content of columns\n",
    "print(df.head())\n",
    "## Number of queries are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We extract unique queries and their count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this code dose not handle whitespaces to identify unique queries. after parsing queries I use parse tree to identify unique queries. current step is only for optimizing query parsing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique queries extracted with counts and written to unique_queries_with_counts.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def extract_unique_queries(input_file, output_file):\n",
    "    try:\n",
    "        # Initialize a dictionary to store query counts\n",
    "        query_counts = {}\n",
    "\n",
    "        with open(input_file, 'r', newline='\\n', encoding='utf-8') as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "\n",
    "            # Iterate through the rows and count queries\n",
    "            for row in reader:\n",
    "                query = row['query']  # Assuming 'query' is the correct column name\n",
    "                query_counts[query] = query_counts.get(query, 0) + 1\n",
    "\n",
    "        # Sort queries and their counts based on the count column in descending order\n",
    "        sorted_queries = sorted(query_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        # Write sorted queries and their counts to the output CSV file\n",
    "        with open(output_file, 'w', newline='\\n', encoding='utf-8') as outfile:\n",
    "            writer = csv.writer(outfile, lineterminator='\\n')\n",
    "            writer.writerow(['query', 'count'])  # Write header\n",
    "\n",
    "            for query, count in sorted_queries:\n",
    "                writer.writerow([query, count])\n",
    "\n",
    "        print(\"Unique queries extracted with counts and written to\", output_file)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Input CSV file not found.\")\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "\n",
    "# Replace 'input_file.csv' with the name of your CSV file and 'output_file.csv' with the desired output filename\n",
    "extract_unique_queries('bio2rdf_sparql_queries.csv', 'unique_queries_with_counts.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT ?drug ?label WHERE { ?drug a &lt;http://bio2rdf.org/drugbank_vocabulary:Drug&gt; . ?drug rdfs:label ?label } LIMIT 10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT ?pathway WHERE { ?pathway a &lt;http://bio2rdf.org/kegg_vocabulary:Pathway&gt; . ?pathway &lt;http://bio2rdf.org/kegg_vocabulary:gene&gt; &lt;http://bio2rdf.org/gene:207&gt; } LIMIT 10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT * WHERE { ?s ?p ?o } LIMIT 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT ?gene ?description WHERE { ?gene a &lt;http://bio2rdf.org/gene_vocabulary:Gene&gt; . ?gene rdfs:description ?description } LIMIT 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT ?disease ?name WHERE { ?disease a &lt;http://bio2rdf.org/omim_vocabulary:Disease&gt; . ?disease rdfs:name ?name } LIMIT 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CONSTRUCT { ?s a &lt;http://bio2rdf.org/gene_vocabulary:Gene&gt; } WHERE { ?s a &lt;http://bio2rdf.org/gene_vocabulary:Gene&gt; } LIMIT 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DESCRIBE &lt;http://bio2rdf.org/drugbank:DB00215&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASK WHERE { &lt;http://bio2rdf.org/omim:100050&gt; a &lt;http://bio2rdf.org/omim_vocabulary:Disease&gt; }</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SELECT ?protein WHERE { ?protein a &lt;http://bio2rdf.org/pro_vocabulary:Protein&gt; . ?protein &lt;http://bio2rdf.org/pro_vocabulary:expressedIn&gt; &lt;http://bio2rdf.org/taxon:9606&gt; } LIMIT 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SELECT ?interaction WHERE { ?interaction a &lt;http://bio2rdf.org/drugbank_vocabulary:Drug-Drug-Interaction&gt; . ?interaction &lt;http://bio2rdf.org/drugbank_vocabulary:drug&gt; &lt;http://bio2rdf.org/drugbank:DB00215&gt; } LIMIT 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SELE * WHERE { ?s ?p ?o } LIMIT 10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SELECT ?disease ?name WHERE { ?disease a &lt;http://bio2rdf.org/omim_vocabulary:Disease&gt; . ?disease rdfs:name ?name</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                      query  \\\n",
       "0                                                                                                    SELECT ?drug ?label WHERE { ?drug a <http://bio2rdf.org/drugbank_vocabulary:Drug> . ?drug rdfs:label ?label } LIMIT 10   \n",
       "1                                             SELECT ?pathway WHERE { ?pathway a <http://bio2rdf.org/kegg_vocabulary:Pathway> . ?pathway <http://bio2rdf.org/kegg_vocabulary:gene> <http://bio2rdf.org/gene:207> } LIMIT 10   \n",
       "2                                                                                                                                                                                      SELECT * WHERE { ?s ?p ?o } LIMIT 10   \n",
       "3                                                                                      SELECT ?gene ?description WHERE { ?gene a <http://bio2rdf.org/gene_vocabulary:Gene> . ?gene rdfs:description ?description } LIMIT 10   \n",
       "4                                                                                               SELECT ?disease ?name WHERE { ?disease a <http://bio2rdf.org/omim_vocabulary:Disease> . ?disease rdfs:name ?name } LIMIT 10   \n",
       "5                                                                                            CONSTRUCT { ?s a <http://bio2rdf.org/gene_vocabulary:Gene> } WHERE { ?s a <http://bio2rdf.org/gene_vocabulary:Gene> } LIMIT 10   \n",
       "6                                                                                                                                                                            DESCRIBE <http://bio2rdf.org/drugbank:DB00215>   \n",
       "7                                                                                                                             ASK WHERE { <http://bio2rdf.org/omim:100050> a <http://bio2rdf.org/omim_vocabulary:Disease> }   \n",
       "8                                      SELECT ?protein WHERE { ?protein a <http://bio2rdf.org/pro_vocabulary:Protein> . ?protein <http://bio2rdf.org/pro_vocabulary:expressedIn> <http://bio2rdf.org/taxon:9606> } LIMIT 10   \n",
       "9   SELECT ?interaction WHERE { ?interaction a <http://bio2rdf.org/drugbank_vocabulary:Drug-Drug-Interaction> . ?interaction <http://bio2rdf.org/drugbank_vocabulary:drug> <http://bio2rdf.org/drugbank:DB00215> } LIMIT 10   \n",
       "10                                                                                                                                                                                       SELE * WHERE { ?s ?p ?o } LIMIT 10   \n",
       "11                                                                                                        SELECT ?disease ?name WHERE { ?disease a <http://bio2rdf.org/omim_vocabulary:Disease> . ?disease rdfs:name ?name    \n",
       "\n",
       "   count  \n",
       "0      4  \n",
       "1      2  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "5      1  \n",
       "6      1  \n",
       "7      1  \n",
       "8      1  \n",
       "9      1  \n",
       "10     1  \n",
       "11     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('unique_queries_with_counts.csv', lineterminator='\\n', dtype=str)\n",
    "\n",
    "print(len(df))\n",
    "df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parse the queries:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- download Node.js from the official website: https://nodejs.org/\n",
    "\n",
    "- Installed Node js \n",
    "\n",
    "- npm install sparqljs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "added 2 packages in 3s\n",
      "\n",
      "1 package is looking for funding\n",
      "  run `npm fund` for details\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!npm install csv-parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "added 1 package, and audited 4 packages in 2s\n",
      "\n",
      "1 package is looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "found 0 vulnerabilities\n"
     ]
    }
   ],
   "source": [
    "!npm install csv-stringify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "# create a python file with following content(mine is called \"optimized_from_js_.py\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def run_script():\n",
    "    # Run the JavaScript code using Node.js as a subprocess\n",
    "    result = subprocess.run(['node', 'optimized.js'], stdout=subprocess.PIPE, text=True)\n",
    "\n",
    "    # Print the output (JSON representation of the parsed SPARQL query)\n",
    "    print(result.stdout)\n",
    "    print('hi')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  In Unix-like operating systems\n",
    "!nohup python optimized_from_js_.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "node:internal/modules/cjs/loader:1080\n",
      "  throw err;\n",
      "  ^\n",
      "\n",
      "Error: Cannot find module 'sparqljs'\n",
      "Require stack:\n",
      "- c:\\Users\\p70073484\\Desktop\\Hackathon\\optimized.js\n",
      "    at Module._resolveFilename (node:internal/modules/cjs/loader:1077:15)\n",
      "    at Module._load (node:internal/modules/cjs/loader:922:27)\n",
      "    at Module.require (node:internal/modules/cjs/loader:1143:19)\n",
      "    at require (node:internal/modules/cjs/helpers:121:18)\n",
      "    at Object.<anonymous> (c:\\Users\\p70073484\\Desktop\\Hackathon\\optimized.js:2:22)\n",
      "    at Module._compile (node:internal/modules/cjs/loader:1256:14)\n",
      "    at Module._extensions..js (node:internal/modules/cjs/loader:1310:10)\n",
      "    at Module.load (node:internal/modules/cjs/loader:1119:32)\n",
      "    at Module._load (node:internal/modules/cjs/loader:960:12)\n",
      "    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:81:12) {\n",
      "  code: 'MODULE_NOT_FOUND',\n",
      "  requireStack: [ 'c:\\\\Users\\\\p70073484\\\\Desktop\\\\Hackathon\\\\optimized.js' ]\n",
      "}\n",
      "\n",
      "Node.js v18.17.1\n"
     ]
    }
   ],
   "source": [
    "# In windows\n",
    "!pythonw optimized_from_js_.py > output90.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051679\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>parsed_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"ASK\",\"where\":[{\"type\":\"bgp\",\"tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"SELECT\",\"variables\":[{\"termType\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"SELECT\",\"variables\":[{\"termType\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"ASK\",\"where\":[{\"type\":\"bgp\",\"tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"SELECT\",\"variables\":[{\"expressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"SELECT\",\"variables\":[{\"expressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"SELECT\",\"variables\":[{\"termType\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"ASK\",\"where\":[{\"type\":\"bgp\",\"tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"SELECT\",\"variables\":[{}],\"where\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-...</td>\n",
       "      <td>{\"queryType\":\"SELECT\",\"variables\":[{}],\"where\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "1  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "2  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "3  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "4  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "5  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "6  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "7  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "8  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "9  PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-...   \n",
       "\n",
       "                                        parsed_query  \n",
       "0  {\"queryType\":\"ASK\",\"where\":[{\"type\":\"bgp\",\"tri...  \n",
       "1  {\"queryType\":\"SELECT\",\"variables\":[{\"termType\"...  \n",
       "2  {\"queryType\":\"SELECT\",\"variables\":[{\"termType\"...  \n",
       "3  {\"queryType\":\"ASK\",\"where\":[{\"type\":\"bgp\",\"tri...  \n",
       "4  {\"queryType\":\"SELECT\",\"variables\":[{\"expressio...  \n",
       "5  {\"queryType\":\"SELECT\",\"variables\":[{\"expressio...  \n",
       "6  {\"queryType\":\"SELECT\",\"variables\":[{\"termType\"...  \n",
       "7  {\"queryType\":\"ASK\",\"where\":[{\"type\":\"bgp\",\"tri...  \n",
       "8  {\"queryType\":\"SELECT\",\"variables\":[{}],\"where\"...  \n",
       "9  {\"queryType\":\"SELECT\",\"variables\":[{}],\"where\"...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "column_names = ['query', 'parsed_query']\n",
    "\n",
    "df = pd.read_csv('parsed.csv', lineterminator='\\n', dtype=str, header=None, names=column_names)\n",
    "\n",
    "print(len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Following code returns valid queries and their parsed tree(removes unvalid):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file_path = 'parsed.csv'\n",
    "output_file_path = 'valid_parsed.csv'\n",
    "\n",
    "# Open the input CSV file for reading\n",
    "with open(input_file_path, 'r', newline='\\n', encoding='utf-8') as input_file:\n",
    "    # Create a CSV reader without header\n",
    "    reader = csv.reader(input_file)\n",
    "    \n",
    "    # Create a list to store valid rows\n",
    "    valid_rows = []\n",
    "    \n",
    "    for row in reader:\n",
    "        # Check if the second column is not equal to 'Error parsing the query'\n",
    "        if len(row) >= 2 and row[1] != 'Error parsing the query.':\n",
    "            valid_rows.append(row)\n",
    "\n",
    "# Open the output CSV file for writing\n",
    "with open(output_file_path, 'w', newline='\\n', encoding='utf-8') as output_file:\n",
    "    # Create a CSV writer with column names\n",
    "    writer = csv.writer(output_file)\n",
    "    \n",
    "    # Write column names\n",
    "    writer.writerow(['query', 'parsed_query'])\n",
    "    \n",
    "    # Write the valid rows\n",
    "    writer.writerows(valid_rows)\n",
    "\n",
    "print(f\"Valid rows have been written to '{output_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "# column_names = ['query', 'parsed_query']\n",
    "\n",
    "df = pd.read_csv('valid_parsed.csv', lineterminator='\\n', dtype=str)\n",
    "\n",
    "print(len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in the 'parsed_query' column: 633453\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('valid_parsed.csv', lineterminator='\\n', dtype=str)\n",
    "\n",
    "# Count unique values in the \"ColumnName\" column\n",
    "unique_count = df['parsed_query\\r'].nunique()\n",
    "\n",
    "print(f\"Number of unique values in the 'parsed_query' column: {unique_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query normalization\n",
    "\n",
    "Global variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df6c06f-e5b3-4d32-9fd7-4ed7958661f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def normalize_sparql_queries(input_csv_path, output_csv_path):\n",
    "    global_var_counter = 1  # Initialize the global variable counter\n",
    "\n",
    "    with open(input_csv_path, 'r') as input_csv, open(output_csv_path, 'w', newline='') as output_csv:\n",
    "        csv_reader = csv.reader(input_csv)\n",
    "        csv_writer = csv.writer(output_csv)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue  # Skip empty rows\n",
    "\n",
    "            sparql_query = row[1]  # Assuming the SPARQL query is in the first column\n",
    "\n",
    "            # Extract variables from the SPARQL query using regular expressions\n",
    "            variables = re.findall(r'\\?([a-zA-Z_][a-zA-Z0-9_]*)', sparql_query)\n",
    "\n",
    "            # Create a mapping of old variables to new numerated variables\n",
    "            variable_mapping = {}\n",
    "            for variable in variables:\n",
    "                if variable not in variable_mapping:\n",
    "                    variable_mapping[variable] = f'?var{global_var_counter}'\n",
    "                    global_var_counter += 1\n",
    "\n",
    "            # Replace variables in the SPARQL query with numerated variables\n",
    "            for old_variable, new_variable in variable_mapping.items():\n",
    "                sparql_query = sparql_query.replace(f'?{old_variable}', new_variable)\n",
    "\n",
    "            # Write the normalized query to the output CSV\n",
    "            csv_writer.writerow([sparql_query])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv_path = \"valid_parsed.csv\"  # Replace with the path to your input CSV file\n",
    "    output_csv_path = \"normalized_queries.csv\"  # Replace with the desired output CSV file\n",
    "\n",
    "    normalize_sparql_queries(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdf7fe-5ec0-41fc-a9ac-f7a53c98bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the maximum column width to None to display the entire content of each cell\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('normalized_queries.csv', lineterminator='\\n', dtype=str, header=None)\n",
    "\n",
    "print(len(df))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973f6a37-96e8-44b7-8ef1-81037e7fb698",
   "metadata": {},
   "source": [
    "get a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20e22256-7536-4134-b039-5f3769d67d83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows have been saved to t.csv.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_csv_file = 'find_bug_triples.csv'  # Replace with your input CSV file path\n",
    "output_csv_file = 't.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_csv_file)\n",
    "\n",
    "# Get the first 1000 rows, including the header\n",
    "sample_df = df.head(10 )\n",
    "\n",
    "# Save the sample DataFrame to an output CSV file\n",
    "sample_df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "print(f\"{len(sample_df)} rows have been saved to {output_csv_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dde436-96e1-4ff3-9a4a-a475203b534f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# get triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d422c8fa-56f6-4fcc-9f1a-e619ca89fa1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Load your CSV data from the input file\n",
    "input_csv_file = 'parsed.csv'\n",
    "output_csv_file = 'find_bug_triples.csv'\n",
    "\n",
    "# Create a list to store the triples\n",
    "triples = []\n",
    "\n",
    "# Define a function to extract triples from the parse tree\n",
    "def extract_triples(parse_tree):\n",
    "    if \"triples\" in parse_tree:\n",
    "        for triple in parse_tree[\"triples\"]:\n",
    "            try:\n",
    "                subject = triple[\"subject\"][\"value\"]\n",
    "                predicate = triple[\"predicate\"][\"value\"]\n",
    "                obj = triple[\"object\"][\"value\"]\n",
    "                triples.append((subject, predicate, obj))\n",
    "            except KeyError as e:\n",
    "                print(f\"Error extracting triple: {e}\")\n",
    "                print(\"Offending triple:\", triple)\n",
    "    \n",
    "    # Recursively call the function on child nodes\n",
    "    for key, value in parse_tree.items():\n",
    "        if isinstance(value, dict):\n",
    "            extract_triples(value)\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    extract_triples(item)\n",
    "\n",
    "# Read the CSV file and process each row\n",
    "with open(input_csv_file, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        # Check if there is content in the second column and it doesn't contain the error message\n",
    "        if len(row) > 1 and row[1] and \"Error parsing the query\" not in row[1]:\n",
    "            # Extract triples from the content of the second column\n",
    "            content = row[1]\n",
    "            try:\n",
    "                parse_tree = json.loads(content)\n",
    "                extract_triples(parse_tree)\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle invalid JSON if needed\n",
    "                pass\n",
    "\n",
    "# Write the extracted triples to the output CSV file\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['subject', 'predicate', 'object']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write the triples\n",
    "    for triple in triples:\n",
    "        writer.writerow({'subject': triple[0], 'predicate': triple[1], 'object': triple[2]})\n",
    "\n",
    "print(\"Triples extracted and written to\", output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a5129a-006f-41c1-9845-f8af30cbe4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the input and output file names\n",
    "input_file = 'find_bug_triples.csv'\n",
    "output_file = 'filtered_data.csv'\n",
    "\n",
    "# Open the input data file for reading and the output file for writing\n",
    "with open(input_file, 'r') as input_file, open(output_file, 'w') as output_file:\n",
    "    for line in input_file:\n",
    "        # Split the line into components using tab (',') as the delimiter\n",
    "        components = line.strip().split(',')\n",
    "\n",
    "        # Check if the line has exactly three components (subject, predicate, object)\n",
    "        if len(components) == 3:\n",
    "            # Write complete triples to the output file\n",
    "            output_file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c100c4-ff82-426e-ab3d-7f8c56d392f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "triple patterns are extracted from the queries, and schema elements are then isolated from these triples. Entities that start with 'var' or 'g_' (indicating a blank node as per sparqljs parser), as well as those containing the substring \"nonsensical\", are excluded, ensuring only unique entities are considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2769492e-e51b-4918-97b5-b325275810a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted entities have been saved to extracted_entities.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "input_file_name = 'filtered_data.csv'\n",
    "output_file_name = 'extracted_entities.csv'\n",
    "\n",
    "subjects_and_objects = set()  # Using a set to store unique entities\n",
    "\n",
    "with open(input_file_name, mode ='r') as input_file:\n",
    "    csvReader = csv.reader(input_file)\n",
    "    \n",
    "    # Skip header if there's any\n",
    "    next(csvReader, None)\n",
    "\n",
    "    for row in csvReader:\n",
    "        # Assuming that the subject is the first element and object is the third element in the row\n",
    "        subject, predicate, object_ = row\n",
    "\n",
    "        if not subject.startswith('var') and not subject.startswith('g_') and 'nonsensical' not in subject:\n",
    "            subjects_and_objects.add(subject)\n",
    "            \n",
    "        if not object_.startswith('var') and not object_.startswith('g_') and 'nonsensical' not in object_:\n",
    "            subjects_and_objects.add(object_)\n",
    "\n",
    "# Write the extracted subjects and objects to an output CSV file\n",
    "with open(output_file_name, mode ='w', newline='') as output_file:\n",
    "    csvWriter = csv.writer(output_file)\n",
    "    \n",
    "    # Writing header\n",
    "    csvWriter.writerow(['Entity'])\n",
    "    \n",
    "    # Writing data\n",
    "    for entity in subjects_and_objects:\n",
    "        csvWriter.writerow([entity])\n",
    "\n",
    "print(f\"Extracted entities have been saved to {output_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8829c1d1-e55b-4f25-abe9-a523e8da09ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30920\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entity\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://purl.org/goodrelations/v1#Offering\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLC9A4\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://bio2rdf.org/kegg:K03908\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>http://bio2rdf.org/wormbase:WBGene00198889\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>http://dbpedia.org/resource/Nortriptyline\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SUCLG1\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>http://bio2rdf.org/go.ref_vocabulary:Resource\\r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>http://bio2rdf.org/wormbase:WBGene00017619\\r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0\n",
       "0                                          Entity\\r\n",
       "1                                                \\r\n",
       "2       http://purl.org/goodrelations/v1#Offering\\r\n",
       "3                                          SLC9A4\\r\n",
       "4                  http://bio2rdf.org/kegg:K03908\\r\n",
       "..                                              ...\n",
       "95     http://bio2rdf.org/wormbase:WBGene00198889\\r\n",
       "96      http://dbpedia.org/resource/Nortriptyline\\r\n",
       "97                                         SUCLG1\\r\n",
       "98  http://bio2rdf.org/go.ref_vocabulary:Resource\\r\n",
       "99     http://bio2rdf.org/wormbase:WBGene00017619\\r\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the maximum column width to None to display the entire content of each cell\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('extracted_entities.csv', lineterminator='\\n', dtype=str, header=None)\n",
    "\n",
    "print(len(df))\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd5cc9-4c8d-4cb1-9f99-8991e54fac24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the clusters and the entities belonging to each cluster\n",
    "for i in range(num_clusters):\n",
    "    print(f\"Cluster {i}:\")\n",
    "    print(df[df['cluster'] == i]['Entity'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ec26c-926a-49b0-a59b-6ff2bcb13ee6",
   "metadata": {},
   "source": [
    "# query type of entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d803c-66df-4ec1-8010-1335c51e287c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install SPARQLWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e3988-77b7-41e4-9c9d-147fb5c96989",
   "metadata": {},
   "source": [
    "# get types but if the entity is a type return itself and other types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be7276f9-6cac-403c-b6f4-ba2831b6e817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    " \n",
    "sparql_endpoint = \"http://bio2rdf.org/sparql\"\n",
    "\n",
    "sparql = SPARQLWrapper(sparql_endpoint)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "def is_url(string):\n",
    "    url_regex = re.compile(\n",
    "        r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    )\n",
    "    return re.match(url_regex, string) is not None\n",
    "\n",
    "def execute_query_and_write_results(entity, query, is_entity_url):\n",
    "    try:\n",
    "        sparql.setQuery(query)\n",
    "        results = sparql.query().convert()\n",
    "        types = set()\n",
    "        has_results = bool(results[\"results\"][\"bindings\"])  # Check if the result set is not empty\n",
    "\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            type_value = result.get(\"type\", {}).get(\"value\")\n",
    "            \n",
    "            if type_value:\n",
    "                if type_value in [\"http://www.w3.org/2002/07/owl#Class\", \"http://www.w3.org/2000/01/rdf-schema#Class\"]:\n",
    "                    types.add(entity)\n",
    "                else:\n",
    "                    types.add(type_value)\n",
    " \n",
    "        if has_results and not is_entity_url:\n",
    "            titles_file.write(entity + '\\n')\n",
    "\n",
    "        for type_value in types:\n",
    "            types_file.write(type_value + '\\n')\n",
    "\n",
    "        if not types:\n",
    "            without_type_file.write(entity + '\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing the entity {entity}: {e}\")\n",
    "\n",
    "with open('extracted_entities.csv', mode ='r') as file, \\\n",
    "     open('types1.txt', 'w') as types_file, \\\n",
    "     open('titles1.txt', 'w') as titles_file, \\\n",
    "     open('without_type1.txt', 'w') as without_type_file:\n",
    "\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        entity = row[0].strip()\n",
    "        is_entity_url = is_url(entity)\n",
    "\n",
    "        if is_entity_url:\n",
    "            query = f\"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "\n",
    "                SELECT DISTINCT ?type  \n",
    "                WHERE {{\n",
    "                    <{entity}> rdf:type ?type .\n",
    "                                    }}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "                PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "                PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "                SELECT ?type \n",
    "                WHERE {{ \n",
    "                       ?s dcterms:title \"{entity}\" ;\n",
    "                                rdf:type ?type .\n",
    "                }}\n",
    "            \"\"\"\n",
    "\n",
    "        execute_query_and_write_results(entity, query, is_entity_url)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2d875-46af-4c81-8524-7953c912d6a7",
   "metadata": {},
   "source": [
    "30918 entities reduced to 1030 types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fee555-0670-47e4-9b52-868ffc61e296",
   "metadata": {},
   "source": [
    "## Get properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee05bbf-77fa-4f1f-8593-93316084b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# List of graphs\n",
    "graphs = [\n",
    "\"http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\",\n",
    "\"http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\",\n",
    "\"http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\",\n",
    "\"http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\",\n",
    "\"http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\",\n",
    "\"http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\",\n",
    "\"http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\",\n",
    "\"http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\",\n",
    "\"http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\",\n",
    "\"http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\",\n",
    "\"http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\",\n",
    "\"http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\",\n",
    "\"http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\",\n",
    "\"http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\",\n",
    "\"http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\",\n",
    "\"http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\",\n",
    "\"http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\",\n",
    "\"http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\",\n",
    "\"http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\",\n",
    "\"http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\",\n",
    "\"http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\",\n",
    "\"http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\",\n",
    "\"http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\",\n",
    "\"http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\",\n",
    "\"http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\",\n",
    "\"http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\"]\n",
    "\n",
    "# Function to check if predicate exists in a specific graph of Bio2RDF\n",
    "def check_predicate_in_graph(predicate, graph):\n",
    "    sparql = SPARQLWrapper(\"https://bio2rdf.org/sparql\")\n",
    "    query = f\"ASK FROM <{graph}> {{ ?s <{predicate}> ?o }}\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        return results['boolean']\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying predicate {predicate} in graph {graph}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Lists to hold predicates based on existence in Bio2RDF and errors\n",
    "exists = []\n",
    "does_not_exist = []\n",
    "errors = []\n",
    "\n",
    "# Read predicates from CSV file and check their existence in each Bio2RDF graph\n",
    "with open('Logs_properties.csv', mode='r') as file:\n",
    "    csvFile = csv.reader(file)\n",
    "    for predicate in csvFile:\n",
    "        predicate_found = False\n",
    "        for graph in graphs:\n",
    "            result = check_predicate_in_graph(predicate[0], graph)\n",
    "            if result is True:\n",
    "                exists.append(predicate[0])\n",
    "                predicate_found = True\n",
    "                break\n",
    "            elif result is None:\n",
    "                errors.append(predicate[0])\n",
    "                break\n",
    "        if not predicate_found and predicate[0] not in errors:\n",
    "            does_not_exist.append(predicate[0])\n",
    "\n",
    "# Write predicates that exist in Bio2RDF to a file\n",
    "with open('10_Logs_properties.csv', 'w') as file:\n",
    "    for predicate in exists:\n",
    "        file.write(predicate + '\\n')\n",
    "\n",
    "# Write predicates that do not exist in Bio2RDF to a file\n",
    "with open('10_p_not_in_bio2rdf.txt', 'w') as file:\n",
    "    for predicate in does_not_exist:\n",
    "        file.write(predicate + '\\n')\n",
    "\n",
    "# Print or log predicates that caused errors\n",
    "print(\"Predicates that caused errors:\")\n",
    "for predicate in errors:\n",
    "    print(predicate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fd9093-6ca3-45c3-ba4f-017129e66c49",
   "metadata": {},
   "source": [
    "# Get Schema vocabularies from KG using queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5503a542-2a1d-4bc2-a972-9aac3993bf6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\n",
      "Query returned 92 results.\n",
      "Query returned 74 results.\n",
      "Processing http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\n",
      "Query returned 11 results.\n",
      "Query returned 51 results.\n",
      "Processing http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\n",
      "Query returned 12 results.\n",
      "Query returned 24 results.\n",
      "Processing http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\n",
      "Query returned 2 results.\n",
      "Query returned 13 results.\n",
      "Processing http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\n",
      "Query returned 5 results.\n",
      "Query returned 35 results.\n",
      "Processing http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\n",
      "Query returned 65 results.\n",
      "Query returned 168 results.\n",
      "Processing http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\n",
      "Query returned 77 results.\n",
      "Query returned 150 results.\n",
      "Processing http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\n",
      "Query returned 68 results.\n",
      "Query returned 85 results.\n",
      "Processing http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\n",
      "Query returned 23 results.\n",
      "Query returned 52 results.\n",
      "Processing http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\n",
      "Query returned 14 results.\n",
      "Query returned 71 results.\n",
      "Processing http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\n",
      "Query returned 40 results.\n",
      "Query returned 103 results.\n",
      "Processing http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\n",
      "Query returned 12 results.\n",
      "Query returned 25 results.\n",
      "Processing http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\n",
      "Query returned 10 results.\n",
      "Query returned 31 results.\n",
      "Processing http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\n",
      "Query returned 27 results.\n",
      "Query returned 40 results.\n",
      "Processing http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\n",
      "Query returned 37 results.\n",
      "Query returned 83 results.\n",
      "Processing http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\n",
      "Query returned 23 results.\n",
      "Query returned 57 results.\n",
      "Processing http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\n",
      "Query returned 103 results.\n",
      "Query returned 113 results.\n",
      "Processing http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\n",
      "Query returned 31 results.\n",
      "Query returned 48 results.\n",
      "Processing http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\n",
      "Query returned 15 results.\n",
      "Query returned 36 results.\n",
      "Processing http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\n",
      "Query returned 18 results.\n",
      "Query returned 37 results.\n",
      "Processing http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\n",
      "Query returned 48 results.\n",
      "Query returned 46 results.\n",
      "Processing http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\n",
      "Query returned 15 results.\n",
      "Query returned 38 results.\n",
      "Processing http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\n",
      "Query returned 45 results.\n",
      "Query returned 83 results.\n",
      "Processing http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\n",
      "Query returned 37 results.\n",
      "Query returned 67 results.\n",
      "Processing http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\n",
      "Query returned 13 results.\n",
      "Query returned 42 results.\n",
      "Processing http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\n",
      "Query returned 84 results.\n",
      "Query returned 47 results.\n",
      "Wrote 601 items to 10_Classes_schema.csv\n",
      "Wrote 1106 items to 10_Predicates_schema.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import csv\n",
    "\n",
    "# List of dataset files\n",
    "dataset_files = [\n",
    "\"http://bio2rdf.org/sgd_resource:bio2rdf.dataset.sgd.R3\",\n",
    "\"http://bio2rdf.org/taxonomy_resource:bio2rdf.dataset.taxonomy.R3\",\n",
    "\"http://bio2rdf.org/homologene_resource:bio2rdf.dataset.homologene.R3\",\n",
    "\"http://bio2rdf.org/interpro_resource:bio2rdf.dataset.interpro.R3\",\n",
    "\"http://bio2rdf.org/bioportal_resource:bio2rdf.dataset.bioportal.R3\",\n",
    "\"http://bio2rdf.org/clinicaltrials_resource:bio2rdf.dataset.clinicaltrials.R3\",\n",
    "\"http://bio2rdf.org/kegg_resource:bio2rdf.dataset.kegg.R3\",\n",
    "\"http://bio2rdf.org/pharmgkb_resource:bio2rdf.dataset.pharmgkb.R3\",\n",
    "\"http://bio2rdf.org/hgnc_resource:bio2rdf.dataset.hgnc.R3\",\n",
    "\"http://bio2rdf.org/mesh_resource:bio2rdf.dataset.mesh.R3\",\n",
    "\"http://bio2rdf.org/omim_resource:bio2rdf.dataset.omim.R3\",\n",
    "\"http://bio2rdf.org/sider_resource:bio2rdf.dataset.sider.R3\",\n",
    "\"http://bio2rdf.org/apo_resource:bio2rdf.dataset.apo.R3\",\n",
    "\"http://bio2rdf.org/ctd_resource:bio2rdf.dataset.ctd.R3\",\n",
    "\"http://bio2rdf.org/go_resource:bio2rdf.dataset.go.R3\",\n",
    "\"http://bio2rdf.org/hp_resource:bio2rdf.dataset.hp.R3\",\n",
    "\"http://bio2rdf.org/drugbank_resource:bio2rdf.dataset.drugbank.R3\",\n",
    "\"http://bio2rdf.org/mgi_resource:bio2rdf.dataset.mgi.R3\",\n",
    "\"http://bio2rdf.org/goa_resource:bio2rdf.dataset.goa.R3\",\n",
    "\"http://bio2rdf.org/ndc_resource:bio2rdf.dataset.ndc.R3\",\n",
    "\"http://bio2rdf.org/wormbase_resource:bio2rdf.dataset.wormbase.R3\",\n",
    "\"http://bio2rdf.org/lsr_resource:bio2rdf.dataset.lsr.R3\",\n",
    "\"http://bio2rdf.org/affymetrix_resource:bio2rdf.dataset.affymetrix.R3\",\n",
    "\"http://bio2rdf.org/ncbigene_resource:bio2rdf.dataset.ncbigene.R3\",\n",
    "\"http://bio2rdf.org/eco_resource:bio2rdf.dataset.eco.R3\",\n",
    "\"http://bio2rdf.org/irefindex_resource:bio2rdf.dataset.irefindex.R3\"]\n",
    "\n",
    "# Replace `your_sparql_endpoint` with the actual SPARQL endpoint URL\n",
    "sparql_endpoint = \"http://bio2rdf.org/sparql\"\n",
    "def execute_query(sparql_query):\n",
    "    sparql = SPARQLWrapper(sparql_endpoint)\n",
    "    sparql.setQuery(sparql_query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        print(f\"Query returned {len(results['results']['bindings'])} results.\")  # Diagnostic print\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# This will hold all distinct class types and predicates\n",
    "classes_set = set()\n",
    "predicates_set = set()\n",
    "\n",
    "# Function to write results to CSV\n",
    "def write_results_to_csv(file_name, results_set):\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for item in results_set:\n",
    "            writer.writerow([item])\n",
    "        print(f\"Wrote {len(results_set)} items to {file_name}\")  # Diagnostic print\n",
    "\n",
    "# Loop through dataset files to construct the schema\n",
    "for file_url in dataset_files:\n",
    "    # dataset_uri = extract_dataset_uri(file_url)\n",
    "    # if dataset_uri:\n",
    "        print(f\"Processing {file_url}\")\n",
    "        # Query to find all distinct types\n",
    "        query_types = f\"\"\"\n",
    "        SELECT DISTINCT ?type\n",
    "        FROM <{file_url}>\n",
    "        WHERE {{ ?s a ?type }}\n",
    "        \"\"\"\n",
    "        results_types = execute_query(query_types)\n",
    "        for result in results_types[\"results\"][\"bindings\"]:\n",
    "            classes_set.add(result[\"type\"][\"value\"])\n",
    "        \n",
    "        # Query to find all distinct predicates\n",
    "        query_predicates = f\"\"\"\n",
    "        SELECT DISTINCT ?p\n",
    "        FROM <{file_url}>\n",
    "        WHERE {{ ?s ?p ?o }}\n",
    "        \"\"\"\n",
    "        results_predicates = execute_query(query_predicates)\n",
    "        for result in results_predicates[\"results\"][\"bindings\"]:\n",
    "            predicates_set.add(result[\"p\"][\"value\"])\n",
    "        \n",
    "# Write the results to CSV files\n",
    "write_results_to_csv('10_Classes_schema.csv', classes_set)\n",
    "write_results_to_csv('10_Predicates_schema.csv', predicates_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610c57e-de25-4ce1-baaf-38efc5cb98f8",
   "metadata": {},
   "source": [
    "# Get superclasses as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b52c1532-53ac-4fea-8876-4b21b7d2b3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Initialize the SPARQL wrapper with the endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://bio2rdf.org/sparql\")\n",
    "\n",
    "# Function to get the superclass of a given class\n",
    "def get_superclass(class_uri):\n",
    "    query = \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?superclass\n",
    "    WHERE {\n",
    "      <\"\"\" + class_uri + \"\"\"> rdfs:subClassOf ?superclass .\n",
    "    }\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    # Extract the superclass URIs from the query results\n",
    "    superclasses = [result['superclass']['value'] for result in results[\"results\"][\"bindings\"]]\n",
    "    # print(\"s\")\n",
    "    # print(\"superclasses\", superclasses)\n",
    "    return superclasses\n",
    "\n",
    "# Read the classes from the CSV file\n",
    "classes_df = pd.read_csv('10_superclasses.csv')\n",
    "\n",
    "# This assumes that the first column contains the class URIs\n",
    "class_uris = classes_df.iloc[:, 0].unique()\n",
    "\n",
    "# Get the superclasses for each class URI\n",
    "superclasses_list = []\n",
    "for class_uri in class_uris:\n",
    "    superclasses = get_superclass(class_uri)\n",
    "    superclasses_list.extend(superclasses)\n",
    "\n",
    "# Remove duplicates and write to CSV\n",
    "superclasses_df = pd.DataFrame(list(set(superclasses_list)), columns=['Superclass'])\n",
    "superclasses_df.to_csv('10_sup_superclasses.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb80a9-167a-424e-a1a4-c9c13dc37776",
   "metadata": {},
   "source": [
    "# Get subclasses as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3cadc-21b9-43ec-b737-cf3f73281467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74981ad6-3233-40d9-94f4-f905eae2f02c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n",
      "superclasses ['http://bio2rdf.org/wormbase_vocabulary:Change_of_expression_level-Regulatory-Interaction', 'http://bio2rdf.org/wormbase_vocabulary:Regulatory-Interaction', 'http://bio2rdf.org/wormbase_vocabulary:Change_of_localization-Regulatory-Interaction']\n",
      "s\n",
      "superclasses []\n",
      "s\n",
      "superclasses []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Initialize the SPARQL wrapper with the endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://bio2rdf.org/sparql\")\n",
    "\n",
    "# Function to get the superclass of a given class\n",
    "def get_superclass(class_uri):\n",
    "    query = \"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT DISTINCT ?subclass\n",
    "    WHERE {\n",
    "      ?subclass rdfs:subClassOf <\"\"\" + class_uri + \"\"\"> .\n",
    "    }\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    # Extract the superclass URIs from the query results\n",
    "    superclasses = [result['subclass']['value'] for result in results[\"results\"][\"bindings\"]]\n",
    "    # print(\"s\")\n",
    "    # print(\"superclasses\", superclasses)\n",
    "    return superclasses\n",
    "\n",
    "# Read the classes from the CSV file\n",
    "classes_df = pd.read_csv('10_subclass.csv')\n",
    "\n",
    "# This assumes that the first column contains the class URIs\n",
    "class_uris = classes_df.iloc[:, 0].unique()\n",
    "\n",
    "# Get the superclasses for each class URI\n",
    "superclasses_list = []\n",
    "for class_uri in class_uris:\n",
    "    superclasses = get_superclass(class_uri)\n",
    "    superclasses_list.extend(superclasses)\n",
    "\n",
    "# Remove duplicates and write to CSV\n",
    "superclasses_df = pd.DataFrame(list(set(superclasses_list)), columns=['Superclass'])\n",
    "superclasses_df.to_csv('10_sub_subclass.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed59553-2d79-4508-9f18-87221ad37ca1",
   "metadata": {
    "tags": []
   },
   "source": [
    " ##  clean schema classes [KG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "69619d7a-23e2-4f39-b633-bb89d94dd085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows have been written to 10_bio2rdf_spesific_Classes_schema.csv as per the conditions.\n",
      "count is: 527\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the input and output filenames\n",
    "input_filename = '10_Classes_schema.csv'\n",
    "output_filename = '10_bio2rdf_spesific_Classes_schema.csv'\n",
    "count = 0\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_filename, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "        open(output_filename, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "\n",
    "    # Create reader and writer objects\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Iterate over each row in the input CSV\n",
    "    for row in reader:\n",
    "        # Check each cell in the row\n",
    "        for value in row:\n",
    "            # If the cell contains '_vocabulary' or contains 'http:' without ':', write the row to the output CSV\n",
    "#             or ('http:' in value and ':' not in value.replace('http:', ''))\n",
    "            if '_vocabulary' in value :\n",
    "                writer.writerow(row)\n",
    "                count = count + 1\n",
    "                break  # We write the row once if it meets the condition and then move to the next row\n",
    "\n",
    "print(f\"Rows have been written to {output_filename} as per the conditions.\")\n",
    "print(\"count is:\", count )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41640bee-f3bb-4718-8b4e-b3ef1c6ff7c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## get the entities that are in kg schema but not in queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf9707-0d97-419b-9a57-f4eb98247e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"10_bio2rdf_total_schema_elements.txt\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open(\"types20.csv\", \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 3: Write the existing entities to `EntitiesInQueriesExist_in_KG_schema.csv`\n",
    "with open(\"typesInQueriesExist_in_KG_schema.csv\", \"w\", newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    for entity in entities_in_kg:\n",
    "        csv_writer.writerow([entity])\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of entities in queries that exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d41090-62f9-47f9-9c0e-a9586bfa5804",
   "metadata": {},
   "source": [
    "\n",
    "## get the entities that are in queries but not in kg schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae001680-a3d5-4ebf-a6eb-8ea5533ff1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities in queries that not exist in KG schema: 4\n",
      "\n",
      "Entities that don't exist in KG schema:\n",
      "http://bio2rdf.org/hgnc_vocabulary:Status\n",
      "http://bio2rdf.org/drugbank_vocabulary:7cab3885cdbcb9df8c405e9c9ad10732\n",
      "http://bio2rdf.org/hgnc_vocabulary:Approved\n",
      "http://bio2rdf.org/atmo_vocabulary:Resource\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"types20.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open( \"10_sup_bio2rdf_spesific_Classes_schema.csv\" , \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 3: Write the existing entities to `EntitiesInQueriesExist_in_KG_schema.csv`\n",
    "with open(\"queries_types_valid_KG_schema.csv\", \"w\", newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    for entity in entities_in_kg:\n",
    "        csv_writer.writerow([entity])\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of entities in queries that not exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a9954-f749-4931-946e-1592ffc4f3c0",
   "metadata": {},
   "source": [
    " ##  clean properties extracted from queries [Logs_properties.csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546f287a-6681-4c67-93c4-3aca488a992e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of properties in queries that not exist in KG schema: 198\n",
      "\n",
      " properties that don't exist in KG schema:\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftXmlIndex\n",
      "http://purl.org/goodrelations/v1#includes\n",
      "http://www.w3.org/ns/dcat#downloadURL\n",
      "http://semanticscience.org/resource/SIO_000205\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSuperFormats\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCmpFuncName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcAlias\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfMapsOnlyNullToNull\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsMatchingFlags\n",
      "http://www.w3.org/ns/dcat#theme\n",
      "http://www.w3.org/2000/01/rdf-schema#domain\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIidOfShortTmpl\n",
      "http://purl.org/dc/terms/accrualPeriodicity\n",
      "http://purl.org/dc/terms/hasPart\n",
      "http://rdfs.org/ns/void#propertyPartition\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000008\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_5\n",
      "http://rdfs.org/ns/void#exampleResource\n",
      "http://rdfs.org/ns/void#vocabulary\n",
      "http://www.w3.org/ns/sparql-service-description#feature\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfStrsqlvalOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrLanguage\n",
      "http://www.bigdata.com/rdf#/features/KB/Namespace\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_2\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftColumnName\n",
      "http://purl.org/ontology/wi/core#evidence\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfName\n",
      "http://xmlns.com/foaf/0.1/logo\n",
      "http://www.w3.org/2000/01/rdf-schema#type\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfUriTmpl\n",
      "http://purl.org/goodrelations/v1#acceptedPaymentMethods\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmPredicateMap\n",
      "http://purl.org/pav/retrievedFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDtpOfNiceSqlval\n",
      "http://semanticscience.org/resource/SIO_010078\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFText\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftAlias\n",
      "http://rdfs.org/ns/void#subjectsTarget\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenEqToSql\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfTypedsqlvalTmpl\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_4\n",
      "http://purl.org/dc/terms/extent\n",
      "http://www.openlinksw.com/schemas/virtrdf#inheritFrom\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_3\n",
      "http://www.openlinksw.com/schemas/virtrdf#item\n",
      "http://rdfs.org/ns/void#sparqlEndpoint\n",
      "http://www.w3.org/2002/07/owl#complementOf\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1\n",
      "http://semanticscience.org/resource/SIO_000341\n",
      "http://www.w3.org/2000/01/rdf-schema#range\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsuriOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsBijection\n",
      "http://purl.org/pav/createdWith\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#TEL\n",
      "http://xmlns.com/foaf/0.1/maker\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmTableName\n",
      "http://purl.org/goodrelations/v1#hasPriceSpecification\n",
      "http://rdfs.org/ns/void#properties\n",
      "http://purl.org/pav/authoredOn\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsUserMaps\n",
      "http://purl.org/goodrelations/v1#validFrom\n",
      "http://www.w3.org/2000/01/rdf-schema#isDescribedUsing\n",
      "http://rdfs.org/ns/void#uriSpace\n",
      "http://purl.org/goodrelations/v1#amountOfThisGood\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Street\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#ADR\n",
      "http://purl.org/dc/terms/conformsTo\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFormat\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfLongTmpl\n",
      "http://rdfs.org/ns/void#distinctSubjects\n",
      "http://www.w3.org/ns/sparql-service-description#endpoint\n",
      "http://www.openlinksw.com/schemas/virtrdf#isSpecialPredicate\n",
      "http://purl.org/dc/terms/references\n",
      "http://purl.org/pav/importedOn\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolOfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000772\n",
      "http://www.w3.org/ns/sparql-service-description#defaultDataset\n",
      "http://purl.org/goodrelations/v1#validThrough\n",
      "http://purl.org/goodrelations/v1#hasBusinessFunction\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsrefOfShortTmpl\n",
      "http://purl.org/dc/terms/issued\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypemaxTmpl\n",
      "http://semanticscience.org/resource/SIO_000062\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalOfShortTmpl\n",
      "http://purl.uniprot.org/core/organism\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsnumericOfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000095\n",
      "http://semanticscience.org/resource/SIO_000300\n",
      "http://purl.org/dc/terms/createdBy\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIslitOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsStable\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfSqlvalTmpl\n",
      "http://purl.org/goodrelations/v1#BusinessEntity\n",
      "http://www.w3.org/2004/02/skos/core#exactMatch\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfLongTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#loadAs\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfColumnCount\n",
      "http://purl.org/goodrelations/v1#availableAtOrFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumns\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageOfShortTmpl\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#City\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaAlias\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfWrapDistinct\n",
      "http://purl.org/goodrelations/v1#hasUnitOfMeasurement\n",
      "http://www.openlinksw.com/schemas/virtrdf#noInherit\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01uriOfShortTmpl\n",
      "http://purl.org/dc/terms/language\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsblankOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongTmpl\n",
      "http://rdfs.org/ns/void#linkPredicate\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect\n",
      "http://purl.org/dc/terms/isVersionOf\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmMatchingFlags\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#EMAIL\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmGraphMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenRef\n",
      "http://semanticscience.org/resource/SIO_000628\n",
      "http://www.w3.org/ns/sparql-service-description#defaultGraph\n",
      "http://purl.org/goodrelations/v1#availableDeliveryMethods\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvATables\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCustomString1\n",
      "http://purl.org/pav/authoredBy\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmObjectMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcColumnName\n",
      "http://purl.org/pav/version\n",
      "http://rdfs.org/ns/void#objectsTarget\n",
      "http://rdfs.org/ns/void#entities\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmSubjectMap\n",
      "http://purl.org/pav/createdBy\n",
      "http://semanticscience.org/resource/SIO_000253\n",
      "http://purl.org/goodrelations/v1#includesObject\n",
      "http://purl.org/goodrelations/v1#eligibleRegions\n",
      "http://purl.org/goodrelations/v1#legalName\n",
      "http://purl.org/goodrelations/v1#eligibleCustomerTypes\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Pcode\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfTypedsqlvalTmpl\n",
      "http://www.w3.org/2002/07/owl#versionInfo\n",
      "http://rdfs.org/ns/void#classPartition\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01blankOfShortTmpl\n",
      "http://purl.org/dc/terms/rightsHolder\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrDatatype\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfUriTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrRestrictions\n",
      "http://purl.org/pav/2.0/version\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfUriOfShortTmpl\n",
      "http://rdfs.org/ns/void#class\n",
      "http://purl.org/pav/lastUpdateOn\n",
      "http://www.w3.org/ns/sparql-service-description#supportedLanguage\n",
      "http://www.w3.org/ns/sparql-service-description#url\n",
      "http://rdfs.org/ns/void#triples\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLong\n",
      "http://xmlns.com/foaf/0.1/homepage\n",
      "http://xmlns.com/foaf/0.1/mbox\n",
      "http://www.openlinksw.com/schemas/virtrdf#version\n",
      "http://rdfs.org/ns/void#property\n",
      "http://purl.org/goodrelations/v1#offers\n",
      "http://www.openlinksw.com/schemas/DAV#ownerUser\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvGeo\n",
      "http://www.w3.org/ns/sparql-service-description#resultFormat\n",
      "http://www.w3.org/2002/07/owl#priorVersion\n",
      "http://semanticscience.org/resource/SIO_000001\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeTmpl\n",
      "http://purl.org/pav/createdOn\n",
      "http://xmlns.com/foaf/0.1/primaryTopic\n",
      "http://www.openlinksw.com/schemas/virtrdf#catName\n",
      "http://rdfs.org/ns/void#classes\n",
      "http://www.w3.org/ns/prov#wasDerivedFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfOkForAnySqlvalue\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#isGcResistantType\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Country\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsDefaultMap\n",
      "http://rdfs.org/ns/void#distinctObjects\n",
      "http://semanticscience.org/resource/SIO_000216\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumnsFormKey\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypeminTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#inputFormat\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftConds\n",
      "http://www.w3.org/2004/02/skos/core#closeMatch\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfHasCheapSqlval\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfNiceSqlvalTmpl\n",
      "http://purl.org/goodrelations/v1#typeOfGood\n",
      "http://rdfs.org/ns/void#subset\n",
      "http://xmlns.com/foaf/0.1/name\n",
      "http://www.w3.org/ns/dcat#byteSize\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSubFormatForRefs\n",
      "http://purl.org/dc/terms/modified\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"Logs_properties.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open( \"10_Predicates_schema.csv\" , \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 3: Write the existing entities to `EntitiesInQueriesExist_in_KG_schema.csv`\n",
    "with open(\"queries_valid_properties_KG_schema.csv\", \"w\", newline='') as csv_output:\n",
    "    csv_writer = csv.writer(csv_output)\n",
    "    for entity in entities_in_kg:\n",
    "        csv_writer.writerow([entity])\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of properties in queries that not exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "\n",
    "print(\"\\n properties that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284b262-99c8-44d2-b5f6-02e9e6e93281",
   "metadata": {},
   "source": [
    "# Get total schema element of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1e94e7-d58a-4613-8b61-c6280fcd7770",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606 unique elements have been written to unique_elements.txt\n"
     ]
    }
   ],
   "source": [
    "# Set to hold the unique elements from both files\n",
    "unique_elements = set()\n",
    "\n",
    "# Read the property_types.txt file and add its contents to the set\n",
    "with open('queries_valid_properties_KG_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())  # strip() removes any leading/trailing whitespace including newline characters\n",
    "\n",
    "# Read the types1.csv file and add its contents to the set\n",
    "with open('queries_types_valid_KG_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())\n",
    "\n",
    "# Write the unique elements to a new file\n",
    "with open('Logs_total_schema_elements.txt', 'w') as file:\n",
    "    for element in unique_elements:\n",
    "        file.write(element + '\\n')\n",
    "\n",
    "print(f\"{len(unique_elements)} unique elements have been written to unique_elements.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935925b4-3c7d-4d22-b405-26d5dca9bc5d",
   "metadata": {},
   "source": [
    "# Get total schema element count of bio2rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ba517f93-25a4-4c7a-b186-6b327dd711ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1635 unique elements have been written to unique_elements.txt\n"
     ]
    }
   ],
   "source": [
    "# Set to hold the unique elements from both files\n",
    "unique_elements = set()\n",
    "\n",
    "# Read the property_types.txt file and add its contents to the set\n",
    "with open('10_sup_bio2rdf_spesific_Classes_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())  # strip() removes any leading/trailing whitespace including newline characters\n",
    "\n",
    "# Read the types1.csv file and add its contents to the set\n",
    "with open('10_Predicates_schema.csv', 'r') as file:\n",
    "    for line in file:\n",
    "        unique_elements.add(line.strip())\n",
    "\n",
    "# Write the unique elements to a new file\n",
    "with open('10_bio2rdf_total_schema_elements.txt', 'w') as file:\n",
    "    for element in unique_elements:\n",
    "        file.write(element + '\\n')\n",
    "\n",
    "print(f\"{len(unique_elements)} unique elements have been written to unique_elements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550ec66d-da33-4425-ab77-352d491a61d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities in queries that exist in KG schema: 202\n",
      "\n",
      "Entities that don't exist in KG schema:\n",
      "http://rdfs.org/ns/void#subjectsTarget\n",
      "http://rdfs.org/ns/void#property\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFormat\n",
      "http://purl.org/dc/terms/modified\n",
      "http://www.w3.org/2002/07/owl#priorVersion\n",
      "http://purl.org/dc/terms/hasPart\n",
      "http://bio2rdf.org/hgnc_vocabulary:Approved\n",
      "http://www.bigdata.com/rdf#/features/KB/Namespace\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfUriOfShortTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#resultFormat\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfUriTmpl\n",
      "http://purl.org/goodrelations/v1#legalName\n",
      "http://purl.org/goodrelations/v1#availableDeliveryMethods\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfColumnCount\n",
      "http://rdfs.org/ns/void#classes\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsBijection\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_4\n",
      "http://purl.org/ontology/wi/core#evidence\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfTypedsqlvalTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#defaultDataset\n",
      "http://www.w3.org/2000/01/rdf-schema#isDescribedUsing\n",
      "http://purl.org/pav/authoredBy\n",
      "http://purl.org/goodrelations/v1#BusinessEntity\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfOkForAnySqlvalue\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsuriOfShortTmpl\n",
      "http://semanticscience.org/resource/SIO_000008\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvFText\n",
      "http://rdfs.org/ns/void#exampleResource\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenRef\n",
      "http://www.openlinksw.com/schemas/virtrdf#isGcResistantType\n",
      "http://rdfs.org/ns/void#classPartition\n",
      "http://www.w3.org/ns/dcat#theme\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIslitOfShortTmpl\n",
      "http://www.w3.org/ns/sparql-service-description#supportedLanguage\n",
      "http://semanticscience.org/resource/SIO_000300\n",
      "http://purl.org/goodrelations/v1#typeOfGood\n",
      "http://rdfs.org/ns/void#objectsTarget\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsnumericOfShortTmpl\n",
      "http://purl.org/goodrelations/v1#eligibleCustomerTypes\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmTableName\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_1\n",
      "http://www.w3.org/2004/02/skos/core#exactMatch\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCmpFuncName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrDatatype\n",
      "http://www.w3.org/2000/01/rdf-schema#domain\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftColumnName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftConds\n",
      "http://www.openlinksw.com/schemas/virtrdf#loadAs\n",
      "http://www.openlinksw.com/schemas/virtrdf#catName\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#TEL\n",
      "http://purl.org/goodrelations/v1#availableAtOrFrom\n",
      "http://xmlns.com/foaf/0.1/maker\n",
      "http://xmlns.com/foaf/0.1/logo\n",
      "http://purl.org/dc/terms/accrualPeriodicity\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmSubjectMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSuperFormats\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalTmpl\n",
      "http://www.w3.org/2004/02/skos/core#closeMatch\n",
      "http://www.w3.org/ns/sparql-service-description#url\n",
      "http://rdfs.org/ns/void#distinctObjects\n",
      "http://rdfs.org/ns/void#properties\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLong\n",
      "http://xmlns.com/foaf/0.1/mbox\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsblankOfShortTmpl\n",
      "http://www.w3.org/2002/07/owl#versionInfo\n",
      "http://rdfs.org/ns/void#vocabulary\n",
      "http://purl.org/dc/terms/issued\n",
      "http://www.w3.org/ns/sparql-service-description#feature\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmPredicateMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfMapsOnlyNullToNull\n",
      "http://bio2rdf.org/drugbank_vocabulary:7cab3885cdbcb9df8c405e9c9ad10732\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfWrapDistinct\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfUriTmpl\n",
      "http://purl.org/pav/2.0/version\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftAlias\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_5\n",
      "http://semanticscience.org/resource/SIO_000628\n",
      "http://bio2rdf.org/hgnc_vocabulary:Status\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#EMAIL\n",
      "http://www.w3.org/2000/01/rdf-schema#type\n",
      "http://www.openlinksw.com/schemas/virtrdf#item\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcColumnName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrLanguage\n",
      "http://purl.org/pav/createdBy\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfValRange-rvrRestrictions\n",
      "http://purl.org/pav/version\n",
      "http://www.openlinksw.com/schemas/virtrdf#noInherit\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsMatchingFlags\n",
      "http://purl.org/goodrelations/v1#eligibleRegions\n",
      "http://purl.org/dc/terms/language\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSubFormatForRefs\n",
      "http://xmlns.com/foaf/0.1/name\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypemaxTmpl\n",
      "http://purl.uniprot.org/core/organism\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmGraphMap\n",
      "http://www.openlinksw.com/schemas/virtrdf#version\n",
      "http://www.openlinksw.com/schemas/DAV#ownerUser\n",
      "http://bio2rdf.org/atmo_vocabulary:Resource\n",
      "http://purl.org/goodrelations/v1#acceptedPaymentMethods\n",
      "http://semanticscience.org/resource/SIO_000062\n",
      "http://purl.org/pav/authoredOn\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvTmpl\n",
      "http://purl.org/pav/importedOn\n",
      "http://purl.org/goodrelations/v1#includesObject\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvATables\n",
      "http://purl.org/dc/terms/isVersionOf\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDatatypeTmpl\n",
      "http://www.w3.org/ns/prov#wasDerivedFrom\n",
      "http://purl.org/goodrelations/v1#hasUnitOfMeasurement\n",
      "http://purl.org/goodrelations/v1#includes\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsSubformatOfLongWhenEqToSql\n",
      "http://purl.org/pav/createdWith\n",
      "http://xmlns.com/foaf/0.1/primaryTopic\n",
      "http://purl.org/pav/retrievedFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfStrsqlvalOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvftXmlIndex\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Street\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Country\n",
      "http://rdfs.org/ns/void#triples\n",
      "http://purl.org/goodrelations/v1#hasBusinessFunction\n",
      "http://semanticscience.org/resource/SIO_000216\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfTypeminTmpl\n",
      "http://purl.org/goodrelations/v1#amountOfThisGood\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfCustomString1\n",
      "http://www.openlinksw.com/schemas/virtrdf#inheritFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfNiceSqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfDtpOfNiceSqlval\n",
      "http://www.w3.org/2000/01/rdf-schema#range\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvcAlias\n",
      "http://purl.org/goodrelations/v1#validFrom\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSparqlEbvOfShortTmpl\n",
      "http://purl.org/dc/terms/extent\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumnsFormKey\n",
      "http://semanticscience.org/resource/SIO_000095\n",
      "http://www.w3.org/ns/dcat#downloadURL\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmObjectMap\n",
      "http://purl.org/dc/terms/conformsTo\n",
      "http://www.w3.org/ns/sparql-service-description#inputFormat\n",
      "http://semanticscience.org/resource/SIO_000205\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfExistingShortOfLongTmpl\n",
      "http://rdfs.org/ns/void#sparqlEndpoint\n",
      "http://semanticscience.org/resource/SIO_000253\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfHasCheapSqlval\n",
      "http://purl.org/dc/terms/references\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsStable\n",
      "http://www.w3.org/ns/sparql-service-description#defaultGraph\n",
      "http://www.w3.org/ns/dcat#byteSize\n",
      "http://rdfs.org/ns/void#propertyPartition\n",
      "http://semanticscience.org/resource/SIO_000001\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfLongTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01uriOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIidOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvGeo\n",
      "http://www.w3.org/2002/07/owl#complementOf\n",
      "http://xmlns.com/foaf/0.1/homepage\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLongOfShortTmpl\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#ADR\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfLanguageOfShortTmpl\n",
      "http://rdfs.org/ns/void#linkPredicate\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfIsrefOfShortTmpl\n",
      "http://rdfs.org/ns/void#class\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfSqlvalTmpl\n",
      "http://purl.org/dc/terms/rightsHolder\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#City\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmf01blankOfShortTmpl\n",
      "http://purl.org/pav/lastUpdateOn\n",
      "http://purl.org/dc/terms/createdBy\n",
      "http://semanticscience.org/resource/SIO_000341\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_3\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvColumns\n",
      "http://semanticscience.org/resource/SIO_000772\n",
      "http://purl.org/goodrelations/v1#offers\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfSqlvalOfShortTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsDefaultMap\n",
      "http://rdfs.org/ns/void#distinctSubjects\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaTableName\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmMatchingFlags\n",
      "http://www.w3.org/2001/vcard-rdf/3.0#Pcode\n",
      "http://rdfs.org/ns/void#entities\n",
      "http://www.openlinksw.com/schemas/virtrdf#isSpecialPredicate\n",
      "http://www.w3.org/ns/sparql-service-description#endpoint\n",
      "http://rdfs.org/ns/void#uriSpace\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfBoolTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfShortOfTypedsqlvalTmpl\n",
      "http://www.openlinksw.com/schemas/virtrdf#qsUserMaps\n",
      "http://semanticscience.org/resource/SIO_010078\n",
      "http://purl.org/pav/createdOn\n",
      "http://purl.org/goodrelations/v1#hasPriceSpecification\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns#_2\n",
      "http://rdfs.org/ns/void#subset\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmvaAlias\n",
      "http://purl.org/goodrelations/v1#validThrough\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read entities from `u_types1_labels.csv`\n",
    "with open(\"Logs_total_schema_elements.txt\" , \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader] # assuming the entity is in the first column\n",
    "\n",
    "# Step 2: Check if they exist in `1u-labels-u-kg-types1.txt`\n",
    "with open( \"10_bio2rdf_total_schema_elements.txt\"  , \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "entities_in_kg = [entity for entity in entities if entity in txt_content]\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "print(f\"Count of entities in queries that exist in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c726546f-6c97-41ad-8acb-e84f0ce189ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities not in KG schema: 54\n",
      "\n",
      "Entities that don't exist in KG schema:\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:limitations-and-caveats\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:ci-upper-limit\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:lower-limit\n",
      "http://bio2rdf.org/obo_vocabulary:Entity\n",
      "http://bio2rdf.org/kegg_vocabulary:Reversible-Reaction\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:ci-upper-limit-na-comment\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:upper-limit\n",
      "http://bio2rdf.org/clinicaltrials_vocabulary:ci-lower-limit\n",
      "http://bio2rdf.org/kegg_vocabulary:Irreversible-Reaction\n",
      "http://bio2rdf.org/broad-lincrna_vocabulary:Resource\n",
      "http://bio2rdf.org/ed_vocabulary:Resource\n",
      "http://bio2rdf.org/ligandbox_vocabulary:Resource\n",
      "http://bio2rdf.org/ncbi-proteinid_vocabulary:Resource\n",
      "http://bio2rdf.org/solgenomics_vocabulary:Resource\n",
      "http://bio2rdf.org/luo_lincrna_vocabulary:Resource\n",
      "http://bio2rdf.org/signalp_vocabulary:Resource\n",
      "http://bio2rdf.org/utoronto_vocabulary:Resource\n",
      "http://bio2rdf.org/v_vocabulary:Resource\n",
      "http://bio2rdf.org/rnacentral_vocabulary:Resource\n",
      "http://bio2rdf.org/phi_vocabulary:Resource\n",
      "http://bio2rdf.org/jcggdb_vocabulary:Resource\n",
      "http://bio2rdf.org/phobius_vocabulary:Resource\n",
      "http://bio2rdf.org/imga_vocabulary:Resource\n",
      "http://bio2rdf.org/id_vocabulary:Resource\n",
      "http://bio2rdf.org/tmhmm_vocabulary:Resource\n",
      "http://bio2rdf.org/ucsc_genes_vocabulary:Resource\n",
      "http://bio2rdf.org/mwsh_vocabulary:Resource\n",
      "http://bio2rdf.org/epcc_vocabulary:Resource\n",
      "http://bio2rdf.org/goc_vocabulary:Resource\n",
      "http://bio2rdf.org/goeco_vocabulary:Resource\n",
      "http://ldf.fi/void-ext#subjectPartition\n",
      "http://www.ontologydesignpatterns.org/ont/dul/DUL.owl#expresses\n",
      "http://www.w3.org/ns/sparql-service-description#namedGraph\n",
      "http://vocabularies.bridgedb.org/ops#objectsDatatype\n",
      "http://vocabularies.bridgedb.org/ops#linksetJustification\n",
      "http://xmlns.com/foaf/0.1/primaryTopicOf\n",
      "http://www.w3.org/ns/dcat#landingPage\n",
      "http://www.openlinksw.com/schemas/virtrdf#qmfUriIdOffset\n",
      "http://www.openlinksw.com/schemas/virtrdf#dialect-exceptions\n",
      "http://www.w3.org/ns/sparql-service-description#name\n",
      "http://ldf.fi/void-ext#datatype\n",
      "http://www.w3.org/ns/prov#wasGeneratedBy\n",
      "http://xmlns.com/foaf/0.1/member\n",
      "http://www.openlinksw.com/schemas/virtrdf#bestRequestMethod\n",
      "http://rdfs.org/ns/void#datadump\n",
      "http://www.w3.org/ns/sparql-service-description#graph\n",
      "http://www.w3.org/ns/dcat#accessURL\n",
      "http://ldf.fi/void-ext#subject\n",
      "http://vocabularies.bridgedb.org/ops#subjectsDatatype\n",
      "http://ldf.fi/void-ext#datatypePartition\n",
      "http://purl.org/pav/previousVersion\n",
      "http://vocabularies.bridgedb.org/ops#assertionMethod\n",
      "http://schema.org/logo\n",
      "http://rdfs.org/ns/void#dataDump\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Read entities from `bio2rdf_total_schema_elements.txt`\n",
    "with open(\"bio2rdf_total_schema_elements.txt\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    entities = [row[0] for row in csv_reader]  # assuming the entity is in the first column\n",
    "\n",
    "# Check if they exist in `Logs_total_schema_elements.txt`\n",
    "with open(\"Logs_total_schema_elements.txt\", \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "# Determine which entities are not in the knowledge graph\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "# Step 4: Print the count and the entities that don't exist\n",
    "# We will sort the entities based on whether they contain '_vocabulary:Resource' or '_vocabulary'\n",
    "resource_entities = [entity for entity in entities_not_in_kg if '_vocabulary:Resource' in entity]\n",
    "vocabulary_entities = [entity for entity in entities_not_in_kg if '_vocabulary' in entity and entity not in resource_entities]\n",
    "other_entities = [entity for entity in entities_not_in_kg if entity not in resource_entities and entity not in vocabulary_entities]\n",
    "\n",
    "# Now we combine the lists, keeping the desired order\n",
    "sorted_entities_not_in_kg = vocabulary_entities + resource_entities + other_entities\n",
    "\n",
    "print(f\"Count of entities not in KG schema: {len(sorted_entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in sorted_entities_not_in_kg:\n",
    "    print(entity)\n",
    "# 10_Subclass_all.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33779f3d-98bf-49fb-b675-01e149dd64e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of entities not in KG schema: 0\n",
      "\n",
      "Entities that don't exist in KG schema:\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Read entities from `10_Subclass_all.csv`\n",
    "entities = []\n",
    "with open(\"10_Subclass_all.csv\", \"r\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        if row:  # Check if row is not empty\n",
    "            entities.append(row[0])  # Assuming the entity is in the first column\n",
    "\n",
    "# Check if they exist in `10_bio2rdf_total_schema_elements.txt`\n",
    "with open(\"10_bio2rdf_total_schema_elements.txt\", \"r\") as txt_file:\n",
    "    txt_content = txt_file.read().splitlines()\n",
    "\n",
    "# Determine which entities are not in the knowledge graph\n",
    "entities_not_in_kg = [entity for entity in entities if entity not in txt_content]\n",
    "\n",
    "print(f\"Count of entities not in KG schema: {len(entities_not_in_kg)}\")\n",
    "print(\"\\nEntities that don't exist in KG schema:\")\n",
    "for entity in entities_not_in_kg:\n",
    "    print(entity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Total Schema Elements (TSE): Count of all distinct classes, predicates in Bio2rdf dataset.\n",
    "\n",
    "Used Schema Elements (USE): Count of all distinct classes, predicates  that are used in user sparql queries.\n",
    "\n",
    "Schema Coverage (SC) = ( USE /  TSE) Ã— 100 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
